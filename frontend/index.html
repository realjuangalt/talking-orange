<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <title>Talking Orange AR</title>
    <script src="./lib/aframe.min.js"></script>
    <script src="./lib/mindar-image-aframe.prod.js"></script>
    <style>
        /* Ensure body doesn't cover the video */
        body {
            margin: 0 !important;
            padding: 0 !important;
            width: 100% !important;
            height: 100% !important;
            overflow: hidden !important;
            background: transparent !important;
        }
        
        html {
            width: 100% !important;
            height: 100% !important;
            overflow: hidden !important;
            background: transparent !important;
        }
        
        /* Project-specific styles will be loaded from project UI files */
        
        /* Prevent zoom on double tap */
        * {
            touch-action: manipulation;
        }
        
        /* Ensure buttons are touch-friendly */
        button {
            min-height: 44px;
            min-width: 44px;
        }
        
        /* Hide MindAR scanning UI overlay */
        .mindar-ui-scanning,
        .mindar-ui-overlay.mindar-ui-scanning,
        .scanning,
        .scanline {
            display: none !important;
            visibility: hidden !important;
            opacity: 0 !important;
        }
        
        /* Make camera view full width */
        a-scene {
            width: 100% !important;
            height: 100% !important;
            position: relative !important;
            z-index: 1 !important;
            background: transparent !important;
        }
        
        /* Ensure video element (camera feed) is full width and visible */
        a-scene video {
            width: 100% !important;
            height: 100% !important;
            object-fit: cover !important;
            position: absolute !important;
            top: 0 !important;
            left: 0 !important;
            z-index: 0 !important;
            display: block !important;
            visibility: visible !important;
            opacity: 1 !important;
            background: #000 !important;
        }
        
        /* Ensure canvas is visible and on top of video */
        a-scene canvas {
            position: absolute !important;
            top: 0 !important;
            left: 0 !important;
            z-index: 1 !important;
            display: block !important;
            visibility: visible !important;
            background: transparent !important;
        }
        
        /* Also target .a-canvas class */
        .a-canvas {
            width: 100% !important;
            height: 100% !important;
            position: absolute !important;
            top: 0 !important;
            left: 0 !important;
            z-index: 1 !important;
            display: block !important;
            visibility: visible !important;
        }
    </style>
</head>
<body>
    <a-scene id="ar-scene" vr-mode-ui="enabled: false" xr-mode-ui="enabled: false" device-orientation-permission-ui="enabled: false" renderer="antialias: true; physicallyCorrectLights: false">
        <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>
        <a-assets id="ar-assets">
            <!-- Media will be loaded dynamically -->
        </a-assets>
        
        <a-entity id="ar-marker" mindar-image-target="targetIndex: 0">
            <!-- Image plane for all states (idle, thinking, talking) -->
            <a-plane id="talking-orange-plane" position="0 0 0.01" height="1" width="1" rotation="9 0 0" 
                     material="shader: flat; transparent: true; alphaTest: 0.1; opacity: 1"
                     visible="true"></a-plane>
        </a-entity>
    </a-scene>
    
    <!-- Burger Menu -->
    <div style="position: fixed; top: 15px; right: 15px; z-index: 1001;">
        <button id="burger-menu-btn" onclick="toggleBurgerMenu()" 
                style="background: rgba(0,0,0,0.5); color: white; border: 1px solid rgba(255,255,255,0.3); padding: 10px; border-radius: 8px; cursor: pointer; font-size: 20px; backdrop-filter: blur(5px); width: 44px; height: 44px; display: flex; align-items: center; justify-content: center;">
            ‚ò∞
        </button>
        
        <!-- Burger Menu Dropdown -->
        <div id="burger-menu" style="position: absolute; top: 54px; right: 0; background: rgba(0,0,0,0.9); border: 1px solid rgba(255,255,255,0.3); border-radius: 8px; padding: 10px; min-width: 180px; display: none; backdrop-filter: blur(10px); box-shadow: 0 4px 12px rgba(0,0,0,0.5);">
            <button onclick="window.location.href='user.html'" 
                    style="width: 100%; background: #2196F3; color: white; border: none; padding: 12px 16px; border-radius: 8px; cursor: pointer; font-size: 14px; font-weight: bold; margin-bottom: 8px; text-align: left;">
                üîê Login / User Home
            </button>
            <button id="language-toggle-menu" onclick="if(window.toggleLanguage) window.toggleLanguage()" 
                    style="width: 100%; background: rgba(255,255,255,0.1); color: white; border: 1px solid rgba(255,255,255,0.3); padding: 12px 16px; border-radius: 8px; cursor: pointer; font-size: 14px; text-align: left;">
                üåç Language: <span id="lang-display">EN</span>
            </button>
        </div>
    </div>
    
    <!-- Language Toggle (Legacy - hidden, kept for compatibility) -->
    <div style="position: fixed; top: 15px; right: 70px; z-index: 1000; display: none;">
        <button id="language-toggle" onclick="toggleLanguage()" 
                style="background: rgba(0,0,0,0.3); color: white; border: 1px solid rgba(255,255,255,0.3); padding: 6px 12px; border-radius: 15px; cursor: pointer; font-size: 12px; font-weight: bold; backdrop-filter: blur(5px);">
            EN
        </button>
    </div>
    
    <!-- Project-Specific UI Container -->
    <!-- This will be populated dynamically when a target is detected -->
    <!-- Hidden by default, shown only when target is detected -->
    <div id="project-ui-container" style="display: none;"></div>
    
    <script>
        // IMMEDIATE TEST - This should appear first in console
        console.log('üö® TEST LOG - Script is executing!');
        console.log('üö® TEST LOG - If you see this, JavaScript is working');
        console.log('üîç MindAR Local Test - Using YOUR targets.mind file');
        
        // Remove VR button immediately and on interval
        function removeVRButton() {
            const vrButton = document.querySelector('.a-enter-vr, .a-enter-vr-button, .a-enter-vr-fullscreen');
            if (vrButton) {
                vrButton.remove();
            }
        }
        setInterval(removeVRButton, 100);
        
        // Time counter - logs every 10 seconds
        // Initialize logging immediately
        console.log('üçä [INIT] Talking Orange AR Application Starting...');
        console.log('üçä [INIT] Console logging is active');
        console.log('üçä [INIT] Browser:', navigator.userAgent);
        console.log('üçä [INIT] Timestamp:', new Date().toISOString());
        
        let appStartTime = Date.now();
        console.log(`‚è±Ô∏è [TIMER] App started at ${new Date().toISOString()}`);
        setInterval(() => {
            const elapsed = Math.floor((Date.now() - appStartTime) / 1000);
            const minutes = Math.floor(elapsed / 60);
            const seconds = elapsed % 60;
            console.log(`‚è±Ô∏è [TIMER] App running: ${minutes}m ${seconds}s (${elapsed}s total)`);
        }, 10000); // Every 10 seconds
        
        // Global variables for AR system
        let availableTargets = [];
        let currentTarget = null;
        let currentTargetMedia = null;
        
        // Function to load project-specific UI
        async function loadProjectUI(userId, projectName) {
            try {
                console.log(`üì¶ Loading project UI for ${userId}/${projectName}...`);
                const uiUrl = `/api/users/${userId}/${projectName}/ui`;
                const response = await fetch(uiUrl);
                
                if (!response.ok) {
                    if (response.status === 404) {
                        console.log(`‚ÑπÔ∏è No project UI file found for ${userId}/${projectName} (this is optional)`);
                        return;
                    }
                    throw new Error(`Failed to load project UI: ${response.status}`);
                }
                
                const uiHtml = await response.text();
                const container = document.getElementById('project-ui-container');
                if (container) {
                    container.innerHTML = uiHtml;
                    container.style.display = 'block'; // Make sure it's visible
                    console.log(`‚úÖ Project UI loaded for ${userId}/${projectName}`);
                    
                    // Update button text after UI loads (if function exists)
                    if (typeof updateButtonText === 'function') {
                        setTimeout(() => updateButtonText(), 100); // Small delay to ensure DOM is ready
                    }
                } else {
                    console.error('‚ùå Project UI container not found');
                }
            } catch (error) {
                console.warn(`‚ö†Ô∏è Error loading project UI: ${error.message}`);
            }
        }
        
        document.addEventListener('DOMContentLoaded', function() {
            console.log('üö® TEST LOG - DOMContentLoaded fired!');
            const scene = document.querySelector('a-scene');
            console.log('üö® TEST LOG - Scene element:', scene);
            
            // Load available targets from API
            loadAvailableTargets().then(() => {
                initializeARSystem();
            });
        });
        
        async function loadAvailableTargets() {
            try {
                console.log('üì° Loading available AR targets...');
                const response = await fetch('/api/targets');
                const data = await response.json();
                
                if (response.ok && data.targets) {
                    availableTargets = data.targets;
                    console.log(`‚úÖ Loaded ${availableTargets.length} AR target(s):`, availableTargets.map(t => t.targetId));
                    
                    // Select first target (or default talking-orange if available)
                    const defaultTarget = availableTargets.find(t => t.userId === 'talking-orange' || t.isDefault) || availableTargets[0];
                    if (defaultTarget) {
                        currentTarget = defaultTarget;
                        currentTargetMedia = defaultTarget.media || [];
                        console.log(`üéØ Selected target: ${currentTarget.targetId} (${currentTarget.userId})`);
                    }
                } else {
                    console.warn('‚ö†Ô∏è No targets found, using fallback');
                    // Fallback to default
                    currentTarget = {
                        targetId: 'talking-orange_default',
                        userId: 'talking-orange',
                        filename: 'targets.mind',
                        url: './media/targets.mind',
                        media: [],
                        isDefault: true
                    };
                }
            } catch (error) {
                console.error('‚ùå Error loading targets:', error);
                // Fallback to default
                currentTarget = {
                    targetId: 'talking-orange_default',
                    userId: 'talking-orange',
                    filename: 'targets.mind',
                    url: './media/targets.mind',
                    media: [],
                    isDefault: true
                };
            }
        }
        
        function initializeARSystem() {
            const scene = document.querySelector('#ar-scene');
            const marker = document.querySelector('#ar-marker');
            const orangePlane = document.querySelector('#talking-orange-plane');
            const assets = document.querySelector('#ar-assets');
            
            console.log('üîç [SCENE] Scene:', scene);
            console.log('üîç [SCENE] Marker:', marker);
            console.log('üîç [SCENE] Orange Plane:', orangePlane);
            
            if (!currentTarget) {
                console.error('‚ùå No target available for AR initialization');
                return;
            }
            
            // Set up MindAR with the selected target
            const targetUrl = currentTarget.url;
            console.log(`üéØ Initializing AR with target: ${targetUrl}`);
            
            scene.setAttribute('mindar-image', `imageTargetSrc: ${targetUrl}; maxTrack: 1; missTolerance: 80; warmupTolerance: 8; filterMinCF: 0.00001; filterBeta: 10000; uiLoading: yes; uiScanning: no; uiError: yes;`);
            
            // Load media assets based on current target
            loadTargetMedia(assets, orangePlane);
            
            console.log('üîç [SCENE] All elements initialized');
            
            // Check Whisper device (CPU/GPU) on startup
            fetch('/api/health')
                .then(response => response.json())
                .then(data => {
                    const deviceInfo = data.whisper_device || {};
                    const device = deviceInfo.device || 'unknown';
                    const useFp16 = deviceInfo.use_fp16 || false;
                    const modelName = deviceInfo.model_name || 'unknown';
                    
                    if (device === 'cuda') {
                        console.log(`üöÄ [WHISPER] Running on GPU (CUDA) - Fast mode enabled`, {
                            device: device,
                            fp16: useFp16,
                            model: modelName
                        });
                    } else if (device === 'cpu') {
                        console.warn(`‚ö†Ô∏è [WHISPER] Running on CPU - This may be slower`, {
                            device: device,
                            fp16: useFp16,
                            model: modelName,
                            note: 'Consider using GPU for better performance'
                        });
                    } else {
                        console.warn(`‚ö†Ô∏è [WHISPER] Device status unknown`, deviceInfo);
                    }
                })
                .catch(error => {
                    console.warn('‚ö†Ô∏è [WHISPER] Could not check device status:', error);
                });
            
            // Wait for scene to be loaded before initializing
            scene.addEventListener('loaded', function() {
                console.log('‚úÖ A-Scene loaded event fired');
                // Small delay to ensure mesh is created
                setTimeout(() => {
                    const mesh = orangePlane ? orangePlane.getObject3D('mesh') : null;
                    if (mesh) {
                        console.log('‚úÖ Mesh is ready');
                    } else {
                        console.warn('‚ö†Ô∏è Mesh not found after scene loaded, will retry on demand');
                    }
                }, 100);
            });
            
            // Initialize immediately (mesh checks will handle readiness)
            // Add MindAR system debugging
            scene.addEventListener('loaded', function() {
                console.log('‚úÖ A-Scene loaded');
                const mindarSystem = scene.systems['mindar-image-system'];
                if (mindarSystem) {
                    console.log('‚úÖ MindAR system found:', mindarSystem);
                    console.log('üìä MindAR config:', {
                        imageTargetSrc: mindarSystem.imageTargetSrc,
                        maxTrack: mindarSystem.maxTrack,
                        missTolerance: mindarSystem.missTolerance,
                        warmupTolerance: mindarSystem.warmupTolerance
                    });
                } else {
                    console.error('‚ùå MindAR system not found!');
                }
            });
            
            // Comprehensive camera and video element logging
            console.log('üìπ [CAMERA] Starting camera diagnostics...');
            
            // Check if mediaDevices is available
            if (!navigator.mediaDevices) {
                console.error('‚ùå [CAMERA] navigator.mediaDevices not available');
            } else {
                console.log('‚úÖ [CAMERA] navigator.mediaDevices available');
            }
            
            // Test camera access (just for diagnostics - MindAR will request its own stream)
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    console.log('‚úÖ [CAMERA] Camera access granted (test)');
                    console.log('üìπ [CAMERA] Stream details:', {
                        id: stream.id,
                        active: stream.active,
                        tracks: stream.getTracks().map(t => ({
                            kind: t.kind,
                            enabled: t.enabled,
                            readyState: t.readyState,
                            settings: t.getSettings()
                        }))
                    });
                    // Stop test stream - MindAR will request its own stream
                    stream.getTracks().forEach(track => {
                        track.stop();
                        console.log(`üõë [CAMERA] Stopped test track: ${track.kind} (MindAR will request its own)`);
                    });
                })
                .catch(err => {
                    console.error('‚ùå [CAMERA] Camera access denied or error:', err);
                    console.error('‚ùå [CAMERA] Error name:', err.name);
                    console.error('‚ùå [CAMERA] Error message:', err.message);
                    alert('Camera access is required for AR. Please grant camera permissions.');
                });
            
            // Monitor video element creation and state
            const checkVideoElement = () => {
                // Check for video elements - MindAR creates them outside the scene sometimes
                // Check both inside scene and in document body
                const videoElementsInScene = scene.querySelectorAll('video');
                const videoElementsInBody = document.querySelectorAll('body video, video');
                const allVideoElements = Array.from(new Set([...videoElementsInScene, ...videoElementsInBody]));
                console.log(`üìπ [VIDEO] Found ${allVideoElements.length} video element(s) total (${videoElementsInScene.length} in scene, ${videoElementsInBody.length} in body)`);
                
                const videoElements = allVideoElements;
                
                videoElements.forEach((video, index) => {
                    console.log(`üìπ [VIDEO] Video element ${index}:`, {
                        id: video.id,
                        src: video.src,
                        srcObject: video.srcObject ? 'has stream' : 'no stream',
                        readyState: video.readyState,
                        videoWidth: video.videoWidth,
                        videoHeight: video.videoHeight,
                        width: video.width,
                        height: video.height,
                        visible: video.offsetParent !== null,
                        display: window.getComputedStyle(video).display,
                        visibility: window.getComputedStyle(video).visibility,
                        opacity: window.getComputedStyle(video).opacity,
                        zIndex: window.getComputedStyle(video).zIndex,
                        position: window.getComputedStyle(video).position
                    });
                    
                    // Check if video has a stream
                    if (video.srcObject) {
                        const stream = video.srcObject;
                        console.log(`üìπ [VIDEO] Video ${index} stream:`, {
                            active: stream.active,
                            tracks: stream.getTracks().length
                        });
                    } else {
                        console.warn(`‚ö†Ô∏è [VIDEO] Video element ${index} has no srcObject (no camera stream attached)`);
                    }
                    
                    // Monitor video events
                    video.addEventListener('loadedmetadata', () => {
                        console.log(`‚úÖ [VIDEO] Video ${index} metadata loaded:`, {
                            videoWidth: video.videoWidth,
                            videoHeight: video.videoHeight,
                            duration: video.duration
                        });
                    });
                    
                    video.addEventListener('playing', () => {
                        console.log(`‚ñ∂Ô∏è [VIDEO] Video ${index} started playing`);
                    });
                    
                    video.addEventListener('pause', () => {
                        console.warn(`‚è∏Ô∏è [VIDEO] Video ${index} paused`);
                    });
                    
                    video.addEventListener('error', (e) => {
                        console.error(`‚ùå [VIDEO] Video ${index} error:`, e);
                    });
                });
                
                // Also check canvas element (A-Frame renders to canvas)
                const canvas = scene.querySelector('canvas');
                if (canvas) {
                    const canvasStyle = window.getComputedStyle(canvas);
                    console.log('üé® [CANVAS] Canvas element found:', {
                        width: canvas.width,
                        height: canvas.height,
                        visible: canvas.offsetParent !== null,
                        display: canvasStyle.display,
                        zIndex: canvasStyle.zIndex,
                        position: canvasStyle.position,
                        opacity: canvasStyle.opacity,
                        backgroundColor: canvasStyle.backgroundColor
                    });
                } else {
                    console.warn('‚ö†Ô∏è [CANVAS] No canvas element found in scene');
                }
                
                // Check body and scene background
                const bodyStyle = window.getComputedStyle(document.body);
                const sceneStyle = window.getComputedStyle(scene);
                console.log('üé® [STYLES] Body styles:', {
                    backgroundColor: bodyStyle.backgroundColor,
                    width: bodyStyle.width,
                    height: bodyStyle.height,
                    overflow: bodyStyle.overflow
                });
                console.log('üé® [STYLES] Scene styles:', {
                    backgroundColor: sceneStyle.backgroundColor,
                    width: sceneStyle.width,
                    height: sceneStyle.height,
                    position: sceneStyle.position,
                    zIndex: sceneStyle.zIndex
                });
            };
            
            // Check video element immediately and periodically
            setTimeout(checkVideoElement, 500); // Check after 500ms
            setTimeout(checkVideoElement, 1000); // Check after 1s
            setTimeout(checkVideoElement, 2000); // Check after 2s
            setTimeout(checkVideoElement, 3000); // Check after 3s
            
            // Also check when scene is loaded
            scene.addEventListener('loaded', () => {
                setTimeout(checkVideoElement, 500);
            });
            
            // Monitor MindAR video element creation
            const checkMindARVideo = () => {
                const mindarSystem = scene.systems['mindar-image-system'];
                if (mindarSystem) {
                    // Check if video exists in system or in DOM
                    const videoInSystem = mindarSystem.video;
                    const videoInDOM = document.querySelector('video');
                    
                    console.log('üìπ [MINDAR] MindAR system video check:', {
                        hasVideoInSystem: !!videoInSystem,
                        hasVideoInDOM: !!videoInDOM,
                        videoElement: videoInSystem ? {
                            readyState: videoInSystem.readyState,
                            videoWidth: videoInSystem.videoWidth,
                            videoHeight: videoInSystem.videoHeight,
                            srcObject: videoInSystem.srcObject ? 'has stream' : 'no stream'
                        } : (videoInDOM ? {
                            readyState: videoInDOM.readyState,
                            videoWidth: videoInDOM.videoWidth,
                            videoHeight: videoInDOM.videoHeight,
                            srcObject: videoInDOM.srcObject ? 'has stream' : 'no stream',
                            display: window.getComputedStyle(videoInDOM).display,
                            visibility: window.getComputedStyle(videoInDOM).visibility
                        } : 'no video element found')
                    });
                    
                    // If video exists but isn't visible, try to make it visible
                    if (videoInDOM) {
                        const videoStyle = window.getComputedStyle(videoInDOM);
                        if (videoStyle.display === 'none' || videoStyle.visibility === 'hidden' || parseFloat(videoStyle.opacity) === 0) {
                            console.warn('‚ö†Ô∏è [VIDEO] Video element found but hidden, attempting to show...', {
                                display: videoStyle.display,
                                visibility: videoStyle.visibility,
                                opacity: videoStyle.opacity
                            });
                            videoInDOM.style.cssText = `
                                display: block !important;
                                visibility: visible !important;
                                opacity: 1 !important;
                                width: 100% !important;
                                height: 100% !important;
                                position: absolute !important;
                                top: 0 !important;
                                left: 0 !important;
                                z-index: 0 !important;
                                object-fit: cover !important;
                            `;
                        }
                    }
                }
            };
            
            // Check MindAR video after system is ready
            const mindarCheckInterval = setInterval(() => {
                if (scene.systems && scene.systems['mindar-image-system']) {
                    checkMindARVideo();
                    clearInterval(mindarCheckInterval);
                }
            }, 200);
            
            // Stop checking after 5 seconds
            setTimeout(() => clearInterval(mindarCheckInterval), 5000);
            
            // Check for MindAR system (check immediately and periodically if not ready)
            const checkMindAR = () => {
                if (scene && scene.systems && scene.systems['mindar-image-system']) {
                    console.log('‚úÖ MindAR system found:', scene.systems['mindar-image-system']);
                    return true;
                }
                return false;
            };
            
            // Check immediately first
            if (!checkMindAR()) {
                // If not ready, check periodically (but don't delay page load)
                const checkInterval = setInterval(() => {
                    if (checkMindAR()) {
                        clearInterval(checkInterval);
                    }
                }, 100); // Check every 100ms instead of waiting 3 seconds
                
                // Stop checking after 5 seconds max
                setTimeout(() => clearInterval(checkInterval), 5000);
            }
        }
        
        function loadTargetMedia(assets, orangePlane) {
            if (!currentTargetMedia || currentTargetMedia.length === 0) {
                console.warn('‚ö†Ô∏è No media files for current target, using default paths');
                // Fallback to default media paths
                loadDefaultMedia(assets);
                return;
            }
            
            console.log(`üì¶ Loading ${currentTargetMedia.length} media files for target...`);
            
            // Find image files for different states
            const images = currentTargetMedia.filter(m => m.type === 'image');
            const smileImg = images.find(m => m.filename.includes('smile')) || images[0];
            const winkImg = images.find(m => m.filename.includes('wink'));
            const thinkingImgs = images.filter(m => m.filename.includes('thinking')).sort();
            const talkingImgs = images.filter(m => m.filename.includes('talking')).sort();
            
            // Create asset elements
            if (smileImg) {
                const img = document.createElement('img');
                img.id = 'talking-orange';
                img.src = smileImg.url;
                assets.appendChild(img);
                orangePlane.setAttribute('src', '#talking-orange');
            }
            
            if (winkImg) {
                const img = document.createElement('img');
                img.id = 'talking-orange-wink';
                img.src = winkImg.url;
                assets.appendChild(img);
            }
            
            thinkingImgs.forEach((imgFile, index) => {
                const img = document.createElement('img');
                img.id = `talking-orange-thinking-${index + 1}`;
                img.src = imgFile.url;
                assets.appendChild(img);
            });
            
            talkingImgs.forEach((imgFile, index) => {
                const img = document.createElement('img');
                img.id = `talking-orange-talking-${index + 1}`;
                img.src = imgFile.url;
                assets.appendChild(img);
            });
            
            // Find video animations and build URLs
            const videoAnimations = currentTargetMedia.filter(m => m.type === 'video_animation');
            console.log(`üìπ Found ${videoAnimations.length} video animation(s)`);
            
                    // Build video animation URLs with user ID and project name
                    const videoAnimUrls = videoAnimations.map(anim => {
                        if (currentTarget && currentTarget.userId && currentTarget.projectName) {
                            return {
                                filename: anim.filename,
                                url: `/api/users/${currentTarget.userId}/${currentTarget.projectName}/media/videos/${anim.filename}/`
                            };
                        } else if (currentTarget && currentTarget.userId) {
                            // Fallback to old structure if no projectName
                            return {
                                filename: anim.filename,
                                url: `/api/users/${currentTarget.userId}/media/videos/${anim.filename}/`
                            };
                        }
                        return anim;
                    });
            
            // Store video animation URLs for later use
            window.targetVideoAnimations = videoAnimUrls;
            window.currentTarget = currentTarget; // Make available globally
            
            // Don't load project UI here - wait for target to be actually detected
            // Project UI will be loaded when targetFound event fires
            
            // If animation module exists, reload frame animations now that we have target info
            if (window.animationModule && typeof window.animationModule.loadFrameAnimations === 'function') {
                console.log('üîÑ Reloading frame animations with target media URLs...');
                // Update paths in animation module based on current target
                if (typeof window.animationModule.updatePathsFromTarget === 'function') {
                    window.animationModule.updatePathsFromTarget();
                }
                window.animationModule.loadFrameAnimations().catch(err => {
                    console.warn('‚ö†Ô∏è Frame animation reload error (non-critical):', err);
                });
            }
            
            // Update animation controller audio URLs with correct project-based paths
            if (window.thinkingController && currentTarget) {
                const thinkingAudioUrl = getAudioUrl('thinking-hmm.mp3');
                if (thinkingAudioUrl && thinkingAudioUrl !== window.thinkingController.audioUrl) {
                    console.log(`üîÑ Updating thinking controller audio URL: ${thinkingAudioUrl}`);
                    window.thinkingController.audioUrl = thinkingAudioUrl;
                }
            }
            
            if (window.talkingController && currentTarget) {
                const currentLang = window.currentLanguage || 'en';
                const introAudioUrl = currentLang === 'es' 
                    ? getAudioUrl('talking-intro-es.mp3')
                    : getAudioUrl('talking-intro.mp3');
                if (introAudioUrl && introAudioUrl !== window.talkingController.introAudioUrl) {
                    console.log(`üîÑ Updating talking controller audio URL: ${introAudioUrl}`);
                    window.talkingController.introAudioUrl = introAudioUrl;
                }
            }
            
            console.log('‚úÖ Target media loaded');
        }
        
        function loadDefaultMedia(assets) {
            // Fallback to default media paths - try to use API if target is available
            const target = window.currentTarget || currentTarget;
            let basePath = './media/';
            
            if (target && target.userId && target.projectName) {
                basePath = `/api/users/${target.userId}/${target.projectName}/media/`;
            } else if (target && target.userId) {
                basePath = `/api/users/${target.userId}/media/`;
            }
            
            const defaultImages = [
                { id: 'talking-orange', src: `${basePath}talking-orange-smile.png` },
                { id: 'talking-orange-wink', src: `${basePath}talking-orange-wink.png` },
                { id: 'talking-orange-thinking-1', src: `${basePath}talking-orange-thinking-1.png` },
                { id: 'talking-orange-thinking-2', src: `${basePath}talking-orange-thinking-2.png` },
                { id: 'talking-orange-talking-1', src: `${basePath}talking-orange-talking-1.png` },
                { id: 'talking-orange-talking-2', src: `${basePath}talking-orange-talking-2.png` },
                { id: 'talking-orange-talking-3', src: `${basePath}talking-orange-talking-3.png` },
                { id: 'talking-orange-talking-4', src: `${basePath}talking-orange-talking-4.png` }
            ];
            
            defaultImages.forEach(imgData => {
                const img = document.createElement('img');
                img.id = imgData.id;
                img.src = imgData.src;
                assets.appendChild(img);
            });
            
            const orangePlane = document.querySelector('#talking-orange-plane');
            if (orangePlane) {
                orangePlane.setAttribute('src', '#talking-orange');
            }
        }
            
            // ========================================
            // TALKING ANIMATION MODULE
            // ========================================
            class TalkingAnimationModule {
                constructor(orangePlane) {
                    this.orangePlane = orangePlane;
                    
                    // Initialize with fallback paths - will be updated when target is loaded
                    this.idleState = { id: '#talking-orange', name: 'smile', src: './media/talking-orange-smile.png' };
                    this.thinkingStates = [
                        { id: '#talking-orange-thinking-1', name: 'thinking-1', src: './media/talking-orange-thinking-1.png' },
                        { id: '#talking-orange-thinking-2', name: 'thinking-2', src: './media/talking-orange-thinking-2.png' }
                    ];
                    
                    // Update paths based on current target if available
                    this.updatePathsFromTarget();
                    
                    // Load talking states dynamically (sorted by number: 1, 2, 3, etc.)
                    this.talkingStates = this.loadTalkingStates();
                    
                    // Load frame-based animations if available (advanced)
                    this.talkingFrames = [];
                    this.thinkingFrames = [];
                    this.talkingTextures = {}; // Cache for preloaded textures
                    this.thinkingTextures = {}; // Cache for preloaded textures
                    this.frameMaterial = null; // Reusable material for frame animations
                    this.useFrameAnimations = false;
                    
                    this.currentThinkingState = 0;
                    this.currentTalkingState = 0;
                    this.currentThinkingFrame = 0;
                    this.currentTalkingFrame = 0;
                    this.talkingDirection = 1; // 1 = forward (opening), -1 = backward (closing)
                    this.fallbackTestMode = false; // When true, fallback animations stop after one cycle
                    this.isTalking = false;
                    this.isThinking = false;
                    this.talkingInterval = null;
                    this.thinkingInterval = null;
                    this.debugMode = true;
                    this.isIdle = true;
                    
                    this.init();
                }
                
                // Update paths based on current target (called after target is loaded)
                updatePathsFromTarget() {
                    const target = window.currentTarget || currentTarget;
                    if (target && target.userId && target.projectName) {
                        // Update idle state path
                        this.idleState.src = `/api/users/${target.userId}/${target.projectName}/media/talking-orange-smile.png`;
                        // Update thinking states paths
                        if (this.thinkingStates.length > 0) {
                            this.thinkingStates[0].src = `/api/users/${target.userId}/${target.projectName}/media/talking-orange-thinking-1.png`;
                        }
                        if (this.thinkingStates.length > 1) {
                            this.thinkingStates[1].src = `/api/users/${target.userId}/${target.projectName}/media/talking-orange-thinking-2.png`;
                        }
                    } else if (target && target.userId) {
                        // Fallback to old structure
                        this.idleState.src = `/api/users/${target.userId}/media/talking-orange-smile.png`;
                        if (this.thinkingStates.length > 0) {
                            this.thinkingStates[0].src = `/api/users/${target.userId}/media/talking-orange-thinking-1.png`;
                        }
                        if (this.thinkingStates.length > 1) {
                            this.thinkingStates[1].src = `/api/users/${target.userId}/media/talking-orange-thinking-2.png`;
                        }
                    }
                    // If no target, keep fallback paths
                }
                
                init() {
                    console.log('üé≠ Initializing Talking Animation Module');
                    // Load frame animations asynchronously (non-blocking)
                    // This allows MindAR to initialize immediately while frames load in background
                    this.loadFrameAnimations().catch(err => {
                        console.warn('‚ö†Ô∏è Frame animation loading error (non-critical):', err);
                    });
                    this.debugImageLoading();
                }
                
                async loadFrameAnimations() {
                    // Try to load frame-based animations from video folders
                    // Optimized: Skip slow discovery - we know there are 145 frames
                    // Just check if first frame exists, then generate all paths
                    try {
                        // Check if target is available - if not, skip (will be called again after target loads)
                        const target = window.currentTarget || currentTarget;
                        if (!target || !target.userId) {
                            console.log('‚è≥ [FRAMES] Target not loaded yet, skipping frame animation loading (will retry after target loads)');
                            return;
                        }
                        
                        // Get base URLs for video animations (will use project-based paths if available)
                        const talkingBaseUrl = this.getVideoBaseUrl('talking-orange-talking-animation');
                        const thinkingBaseUrl = this.getVideoBaseUrl('talking-orange-thinking-animation');
                        
                        console.log(`üîç [FRAMES] Checking frame animations at:`, {
                            talking: talkingBaseUrl,
                            thinking: thinkingBaseUrl
                        });
                        
                        // Quick check if talking animation exists (single HEAD request)
                        try {
                            const talkingResponse = await fetch(`${talkingBaseUrl}frame_00000.png`, { method: 'HEAD' });
                            if (talkingResponse.ok) {
                                // Generate frame paths directly (no sequential discovery needed)
                                this.talkingFrames = this.generateFramePaths('talking-orange-talking-animation', 145);
                                console.log(`‚úÖ Generated ${this.talkingFrames.length} talking animation frame paths`);
                            } else if (talkingResponse.status !== 404) {
                                // Only log non-404 errors (404 is expected if frames don't exist)
                                console.log(`‚ö†Ô∏è [FRAMES] Talking animation check failed at ${talkingBaseUrl}frame_00000.png (status: ${talkingResponse.status})`);
                            }
                        } catch (err) {
                            // Silently handle fetch errors (network issues, CORS, etc.)
                            // Don't log 404s as they're expected if frames don't exist
                            if (!err.message.includes('404') && !err.message.includes('Failed to fetch')) {
                                console.warn(`‚ö†Ô∏è [FRAMES] Error checking talking animation:`, err.message);
                            }
                        }
                        
                        // Quick check if thinking animation exists (single HEAD request)
                        try {
                            const thinkingResponse = await fetch(`${thinkingBaseUrl}frame_00000.png`, { method: 'HEAD' });
                            if (thinkingResponse.ok) {
                                // Generate frame paths directly (no sequential discovery needed)
                                this.thinkingFrames = this.generateFramePaths('talking-orange-thinking-animation', 145);
                                console.log(`‚úÖ Generated ${this.thinkingFrames.length} thinking animation frame paths`);
                            } else if (thinkingResponse.status !== 404) {
                                // Only log non-404 errors (404 is expected if frames don't exist)
                                console.log(`‚ö†Ô∏è [FRAMES] Thinking animation check failed at ${thinkingBaseUrl}frame_00000.png (status: ${thinkingResponse.status})`);
                            }
                        } catch (err) {
                            // Silently handle fetch errors (network issues, CORS, etc.)
                            // Don't log 404s as they're expected if frames don't exist
                            if (!err.message.includes('404') && !err.message.includes('Failed to fetch')) {
                                console.warn(`‚ö†Ô∏è [FRAMES] Error checking thinking animation:`, err.message);
                            }
                        }
                        
                        // Use frame animations if we have them
                        if (this.talkingFrames.length > 0 || this.thinkingFrames.length > 0) {
                            this.useFrameAnimations = true;
                            console.log('üé¨ Using frame-based animations (advanced mode)');
                            
                            // First: Preload images to browser cache (downloads all files)
                            if (this.talkingFrames.length > 0) {
                                console.log('üì• Downloading talking animation images to browser cache...');
                                await this.preloadImagesToCache(this.talkingFrames, 'talking');
                            }
                            if (this.thinkingFrames.length > 0) {
                                console.log('üì• Downloading thinking animation images to browser cache...');
                                await this.preloadImagesToCache(this.thinkingFrames, 'thinking');
                            }
                            
                            // Then: Preload all textures for instant display (images already in cache)
                            if (this.talkingFrames.length > 0) {
                                console.log('üîÑ Preloading talking animation textures...');
                                await this.preloadTextures(this.talkingFrames, this.talkingTextures, 'talking');
                            }
                            if (this.thinkingFrames.length > 0) {
                                console.log('üîÑ Preloading thinking animation textures...');
                                await this.preloadTextures(this.thinkingFrames, this.thinkingTextures, 'thinking');
                            }
                            
                            // Advanced animations fully loaded - show wink as confirmation
                            console.log('‚ú® Advanced animations fully loaded!');
                            this.showWinkConfirmation();
                        } else {
                            console.log('üñºÔ∏è  Using image-based animations (fallback mode)');
                        }
                    } catch (error) {
                        console.log('üñºÔ∏è  Frame animations not found, using image-based animations');
                        this.useFrameAnimations = false;
                    }
                }
                
                // Generate frame paths directly (much faster than sequential discovery)
                generateFramePaths(folderName, frameCount) {
                    const frames = [];
                    // Use user-specific URL if available, otherwise fallback to default
                    const baseUrl = this.getVideoBaseUrl(folderName);
                    for (let i = 0; i < frameCount; i++) {
                        const framePath = `${baseUrl}frame_${String(i).padStart(5, '0')}.png`;
                        frames.push(framePath);
                    }
                    return frames;
                }
                
                getVideoBaseUrl(folderName) {
                    // Check if we have video animations from current target (from window or global)
                    const target = window.currentTarget || currentTarget;
                    if (window.targetVideoAnimations && target) {
                        const videoAnim = window.targetVideoAnimations.find(v => v.filename === folderName);
                        if (videoAnim && videoAnim.url) {
                            // Ensure URL ends with /
                            return videoAnim.url.endsWith('/') ? videoAnim.url : videoAnim.url + '/';
                        }
                    }
                    // Try to construct URL from current target if available (project-based)
                    if (target && target.userId && target.projectName) {
                        return `/api/users/${target.userId}/${target.projectName}/media/videos/${folderName}/`;
                    } else if (target && target.userId) {
                        // Fallback to old structure if no projectName
                        return `/api/users/${target.userId}/media/videos/${folderName}/`;
                    }
                    // Final fallback to default path (shouldn't happen in normal operation)
                    console.warn(`‚ö†Ô∏è [VIDEO] No target context, using fallback path for ${folderName}`);
                    return `./media/videos/${folderName}/`;
                }
                
                // Legacy discovery method (kept for fallback if frame count is unknown)
                async discoverFrames(folderName) {
                    const frames = [];
                    let frameIndex = 0;
                    const baseUrl = this.getVideoBaseUrl(folderName);
                    
                    while (true) {
                        const framePath = `${baseUrl}frame_${String(frameIndex).padStart(5, '0')}.png`;
                        try {
                            // Use HEAD request to check if frame exists without downloading it
                            // This avoids downloading full images just to check existence
                            const response = await fetch(framePath, { 
                                method: 'HEAD',
                                // Suppress error logging for expected 404s
                                cache: 'no-cache'
                            });
                            
                            if (response.ok) {
                                frames.push(framePath);
                                frameIndex++;
                            } else if (response.status === 404) {
                                // Frame doesn't exist - since frames are sequential, we've reached the end
                                break;
                            } else {
                                // Other error (e.g., 403, 500) - also stop
                                break;
                            }
                        } catch (error) {
                            // Network error or other issue - stop searching
                            // This is expected when we reach the end of the sequence
                            break;
                        }
                    }
                    
                    return frames;
                }
                
                async preloadImagesToCache(framePaths, animationType) {
                    // Preload images to browser cache using Image objects
                    // This downloads all files so they're cached when we need them
                    const loadPromises = framePaths.map((framePath, index) => {
                        return new Promise((resolve) => {
                            const img = new Image();
                            img.onload = () => {
                                if ((index + 1) % 20 === 0 || index === framePaths.length - 1) {
                                    console.log(`   ‚úÖ Cached ${index + 1}/${framePaths.length} ${animationType} images`);
                                }
                                resolve();
                            };
                            img.onerror = (error) => {
                                console.warn(`‚ö†Ô∏è Failed to cache ${framePath}`);
                                resolve(); // Continue with other images
                            };
                            img.src = framePath; // Trigger download
                        });
                    });
                    
                    await Promise.all(loadPromises);
                    console.log(`‚úÖ All ${framePaths.length} ${animationType} images cached in browser!`);
                }
                
                async preloadTextures(framePaths, textureCache, animationType) {
                    // Preload all textures in parallel for instant display
                    const loader = new THREE.TextureLoader();
                    const loadPromises = framePaths.map((framePath, index) => {
                        return new Promise((resolve) => {
                            loader.load(
                                framePath,
                                (texture) => {
                                    texture.colorSpace = THREE.SRGBColorSpace;
                                    texture.flipY = true;
                                    
                                    // Preserve aspect ratio - center the texture and maintain proportions
                                    texture.center.set(0.5, 0.5);
                                    // Set repeat to 1,1 to avoid tiling
                                    texture.repeat.set(1, 1);
                                    
                                    textureCache[framePath] = texture;
                                    if ((index + 1) % 20 === 0 || index === framePaths.length - 1) {
                                        console.log(`‚úÖ Preloaded ${index + 1}/${framePaths.length} ${animationType} textures`);
                                    }
                                    resolve();
                                },
                                undefined,
                                (error) => {
                                    console.error(`‚ùå Error preloading ${framePath}:`, error);
                                    resolve(); // Continue loading other frames
                                }
                            );
                        });
                    });
                    
                    await Promise.all(loadPromises);
                    console.log(`‚úÖ All ${framePaths.length} ${animationType} textures preloaded and ready!`);
                }
                
                loadTalkingStates() {
                    // Dynamically load all talking images (talking-orange-talking-N.png)
                    // They're already in assets, we just need to create state objects
                    const states = [];
                    let index = 1;
                    
                    while (true) {
                        const imgElement = document.querySelector(`img[id="talking-orange-talking-${index}"]`);
                        if (imgElement) {
                            states.push({
                                id: `#talking-orange-talking-${index}`,
                                name: `talking-${index}`,
                                src: `./media/talking-orange-talking-${index}.png`
                            });
                            index++;
                        } else {
                            break;
                        }
                    }
                    
                    console.log(`‚úÖ Loaded ${states.length} talking animation states:`, states.map(s => s.name));
                    return states;
                }
                
                setToTalkingState(stateIndex) {
                    if (stateIndex < 0 || stateIndex >= this.talkingStates.length) {
                        console.error(`‚ùå Invalid talking state index: ${stateIndex}`);
                        return;
                    }
                    
                    const state = this.talkingStates[stateIndex];
                    console.log(`üó£Ô∏è Setting to talking state: ${state.name}`);
                    this.applyTextureFromState(state);
                }
                
                debugImageLoading() {
                    console.log('üîç Debugging image loading...');
                    
                    // Check idle state
                    const idleImg = document.querySelector(`img[id="${this.idleState.id.replace('#', '')}"]`);
                    if (idleImg) {
                        console.log(`‚úÖ Idle image (${this.idleState.name}):`, {
                            id: this.idleState.id,
                            src: this.idleState.src,
                            loaded: idleImg.complete
                        });
                    }
                }
                
                setToIdleState() {
                    console.log('üé≠ Setting to idle state (smile)');
                    this.isIdle = true;
                    
                    // Show image plane
                    const imageMesh = this.orangePlane.getObject3D('mesh');
                    if (imageMesh) {
                        imageMesh.visible = true;
                    }
                    
                    // Force apply smile image using direct texture application (not setAttribute to avoid geometry changes)
                    try {
                        this.applyTextureFromState(this.idleState);
                        // Ensure geometry stays at 1x1 (A-Frame's setAttribute('src') can change geometry)
                        this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                        console.log('‚úÖ Idle state applied (smile image)');
                    } catch (error) {
                        console.error('‚ùå Error setting idle state:', error);
                        // Last resort: use src but immediately reset geometry
                        this.orangePlane.setAttribute('src', this.idleState.id);
                        // Force geometry back to 1x1 after src is set
                        setTimeout(() => {
                            this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                        }, 10);
                    }
                }
                
                applyTextureFromState(state) {
                    const img = document.querySelector(`img[id="${state.id.replace('#', '')}"]`);
                    if (!img) {
                        console.error(`‚ùå Image not found: ${state.id}`);
                        return;
                    }
                    
                    this.recreateMaterial(img);
                }
                
                recreateMaterial(img) {
                    try {
                        const mesh = this.orangePlane.getObject3D('mesh');
                        
                        // Wait for mesh to be ready if it doesn't exist yet
                        if (!mesh) {
                            console.warn('‚ö†Ô∏è Mesh not ready yet, waiting for A-Frame to initialize...');
                            // Wait for next frame and try again
                            setTimeout(() => {
                                this.recreateMaterial(img);
                            }, 100);
                            return;
                        }
                        
                        // Keep plane geometry fixed at 1x1 (flat 2D surface)
                        // Reset to 1x1 to ensure consistency
                        this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                        
                        const texture = new THREE.Texture(img);
                        texture.needsUpdate = true;
                        texture.colorSpace = THREE.SRGBColorSpace;
                        texture.flipY = true;
                        
                        // Center the texture - always centered regardless of aspect ratio
                        texture.center.set(0.5, 0.5);
                        texture.repeat.set(1, 1);
                        texture.offset.set(0, 0);
                        
                        // Use MeshBasicMaterial - doesn't respond to lighting (no shading)
                        const material = new THREE.MeshBasicMaterial({
                            map: texture,
                            transparent: true,
                            alphaTest: 0.1,
                            opacity: 1.0,
                            side: THREE.DoubleSide
                        });
                        
                        // Don't dispose materials - just replace them
                        // Disposal can interfere with MindAR's internal state
                        mesh.material = material;
                        
                        // Reset frameMaterial reference since we're now using a different material
                        // This ensures frame animations create a fresh material
                        this.frameMaterial = null;
                        
                    } catch (error) {
                        console.error('‚ùå Error recreating material:', error);
                        // Last resort: use src but immediately reset geometry
                        // Use the proper A-Frame asset reference format
                        const imgId = img.id || img.getAttribute('id');
                        if (imgId) {
                            this.orangePlane.setAttribute('src', `#${imgId}`);
                        // Force geometry back to 1x1 after src is set (A-Frame might change it)
                        setTimeout(() => {
                            this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                        }, 10);
                        } else {
                            console.error('‚ùå Cannot set src: image has no ID');
                        }
                    }
                }
                
                applyTextureFromFrame(framePath) {
                    const mesh = this.orangePlane.getObject3D('mesh');
                    
                    if (!mesh) {
                        console.error('‚ùå Mesh not found in applyTextureFromFrame');
                        return;
                    }
                    
                    // Ensure mesh is visible
                    mesh.visible = true;
                    
                    // Check cache first (preloaded textures)
                    let texture = null;
                    if (this.talkingTextures[framePath]) {
                        texture = this.talkingTextures[framePath];
                    } else if (this.thinkingTextures[framePath]) {
                        texture = this.thinkingTextures[framePath];
                    }
                    
                    if (!texture) {
                        console.warn(`‚ö†Ô∏è Frame texture not cached: ${framePath}`);
                        return;
                    }
                    
                    // Ensure plane geometry stays fixed at 1x1 (flat 2D surface)
                    // Reset to 1x1 to ensure consistency - don't change geometry based on texture
                    this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                    
                    // Ensure texture mapping is correct - center and repeat
                    texture.center.set(0.5, 0.5);
                    texture.repeat.set(1, 1);
                    texture.offset.set(0, 0);
                    
                    // Verify geometry stays at 1x1
                    const geometry = mesh.geometry;
                    if (geometry && (Math.abs(geometry.parameters.width - 1) > 0.01 || 
                                     Math.abs(geometry.parameters.height - 1) > 0.01)) {
                        console.warn(`‚ö†Ô∏è Plane geometry changed from 1x1 to ${geometry.parameters.width}x${geometry.parameters.height}, resetting`);
                        // Force it back to 1x1
                        this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                    }
                    
                    // Check if we need to recreate frameMaterial
                    // This happens when we switched from image-based (smile) back to frame-based animation
                    const needsNewMaterial = !this.frameMaterial || 
                                            mesh.material !== this.frameMaterial ||
                                            (this.frameMaterial && !this.frameMaterial.map);
                    
                    if (needsNewMaterial) {
                        // Don't dispose materials - just replace them
                        // Disposal can interfere with MindAR's internal state
                        
                        // Create fresh frameMaterial
                        this.frameMaterial = new THREE.MeshBasicMaterial({
                            map: texture,
                            transparent: true,
                            alphaTest: 0.1,
                            opacity: 1.0,
                            side: THREE.DoubleSide
                        });
                        mesh.material = this.frameMaterial;
                    } else {
                        // Just update the texture map - much more efficient!
                        // All textures are preloaded and cached, so we never dispose them
                        this.frameMaterial.map = texture;
                        this.frameMaterial.needsUpdate = true;
                    }
                    
                    // Force material update
                    mesh.material.needsUpdate = true;
                    
                    // Ensure mesh is still visible (defensive check)
                    if (!mesh.visible) {
                        console.warn('‚ö†Ô∏è Mesh became invisible, re-enabling');
                        mesh.visible = true;
                    }
                }
                
                showWinkConfirmation() {
                    // Show wink image briefly to confirm advanced animations are loaded
                    // This indicates that test buttons will use frame-based animations, not fallbacks
                    console.log('üòâ Showing wink - advanced animations are ready!');
                    
                    // Wait for mesh to be ready before trying to show wink
                    const checkMesh = () => {
                        const mesh = this.orangePlane.getObject3D('mesh');
                        if (!mesh) {
                            setTimeout(checkMesh, 100);
                            return;
                        }
                        
                    const winkImg = document.querySelector('img[id="talking-orange-wink"]');
                        if (winkImg && winkImg.complete) {
                        this.recreateMaterial(winkImg);
                        // Return to smile after 1 second
                        setTimeout(() => {
                            const smileImg = document.querySelector('img[id="talking-orange"]');
                                if (smileImg && smileImg.complete) {
                                this.recreateMaterial(smileImg);
                                console.log('üòä Returned to smile after wink confirmation');
                            }
                        }, 1000);
                    } else {
                            console.warn('‚ö†Ô∏è Wink image not found or not loaded yet');
                    }
                    };
                    
                    // Start checking after a short delay to ensure A-Frame is ready
                    setTimeout(checkMesh, 500);
                }
                
                setToThinkingState(stateIndex) {
                    if (stateIndex < 0 || stateIndex >= this.thinkingStates.length) {
                        console.error(`‚ùå Invalid thinking state index: ${stateIndex}`);
                        return;
                    }
                    
                    const state = this.thinkingStates[stateIndex];
                    console.log(`ü§î Setting to thinking state: ${state.name}`);
                    this.applyTextureFromState(state);
                }
                
                startTalkingAnimation() {
                    // Force stop any existing thinking animation first
                    if (this.isThinking) {
                        console.log('‚ö†Ô∏è Stopping existing thinking animation before starting talking');
                        this.stopThinkingAnimation();
                    }
                    
                    // Clear any stale intervals
                    if (this.talkingInterval) {
                        clearInterval(this.talkingInterval);
                        this.talkingInterval = null;
                    }
                    
                    // Reset state flags
                    this.isTalking = true;
                    this.isIdle = false;
                    this.isThinking = false; // Ensure thinking is false
                    
                    // Ensure image plane is visible
                    const imageMesh = this.orangePlane.getObject3D('mesh');
                    if (imageMesh) {
                        imageMesh.visible = true;
                    }
                    
                    // Use frame-based animation if available, otherwise fall back to image-based
                    if (this.useFrameAnimations && this.talkingFrames.length > 0) {
                        console.log(`üé¨ Starting frame-based talking animation with ${this.talkingFrames.length} frames`);
                        this.currentTalkingFrame = 0;
                        
                        // Start with first frame
                        this.applyTextureFromFrame(this.talkingFrames[this.currentTalkingFrame]);
                        
                        // Loop forward through frames continuously
                        // 145 frames in 6 seconds = ~41.4ms per frame
                        const talkingFrameInterval = Math.round(6000 / this.talkingFrames.length);
                        console.log(`‚è±Ô∏è  Talking animation: ${this.talkingFrames.length} frames, interval=${talkingFrameInterval}ms, target duration=6s`);
                        
                        let talkingStartTime = performance.now();
                        let talkingFrameCount = 0;
                        this.talkingInterval = setInterval(() => {
                            // Move to next frame
                            this.currentTalkingFrame++;
                            
                            // Check if we've reached the last frame
                            if (this.currentTalkingFrame >= this.talkingFrames.length) {
                                // Check if we're in test mode (should stop after one cycle)
                                if (this.fallbackTestMode) {
                                    console.log(`‚úÖ Talking animation completed (reached frame ${this.talkingFrames.length - 1}) - test mode`);
                                    this.fallbackTestMode = false;
                                    this.stopTalkingAnimation();
                                    return;
                                }
                                // Normal operation: loop continuously
                                this.currentTalkingFrame = 0;
                            }
                            
                            talkingFrameCount++;
                            
                            const elapsed = performance.now() - talkingStartTime;
                            const expectedElapsed = talkingFrameCount * talkingFrameInterval;
                            const timingDiff = (elapsed - expectedElapsed).toFixed(2);
                            
                            if (talkingFrameCount % 10 === 0) {
                                console.log(`üó£Ô∏è Talking frame ${this.currentTalkingFrame} requested [elapsed: ${elapsed.toFixed(0)}ms, expected: ${expectedElapsed.toFixed(0)}ms, diff: ${timingDiff}ms]`);
                            }
                            
                            this.applyTextureFromFrame(this.talkingFrames[this.currentTalkingFrame]);
                        }, talkingFrameInterval); // 6 seconds total for full cycle
                    } else {
                        // Fallback to image-based animation
                        if (this.talkingStates.length === 0) {
                            console.error('‚ùå No talking states available');
                            return;
                        }
                        
                        console.log(`üó£Ô∏è Starting image-based talking animation with ${this.talkingStates.length} states`);
                        this.currentTalkingState = 0;
                        this.talkingDirection = 1;
                        
                        // Start with first talking state
                        this.setToTalkingState(this.currentTalkingState);
                        
                        // Cycle through talking images forward then backward (opening/closing mouth)
                        this.talkingInterval = setInterval(() => {
                            // Check boundaries before moving
                            if (this.currentTalkingState >= this.talkingStates.length - 1 && this.talkingDirection === 1) {
                                this.talkingDirection = -1; // Start closing
                            } else if (this.currentTalkingState <= 0 && this.talkingDirection === -1) {
                                // Completed one full cycle (forward + backward)
                                if (this.fallbackTestMode) {
                                    console.log('‚úÖ Fallback talking animation completed one cycle');
                                    this.fallbackTestMode = false;
                                    this.stopTalkingAnimation();
                                    return;
                                }
                                // Normal operation: continue looping
                                this.talkingDirection = 1; // Start opening again
                            }
                            
                            // Move to next state based on direction
                            this.currentTalkingState += this.talkingDirection;
                            this.setToTalkingState(this.currentTalkingState);
                        }, 100); // Fast animation for mouth movement
                    }
                }
                
                stopTalkingAnimation() {
                    if (!this.isTalking) {
                        console.log('‚ö†Ô∏è Animation not running');
                        // Still reset test mode flag even if not running
                        this.fallbackTestMode = false;
                        return;
                    }
                    
                    this.isTalking = false;
                    console.log('üîá Stopping talking animation, returning to idle');
                    
                    // Clear talking interval immediately
                    if (this.talkingInterval) {
                        clearInterval(this.talkingInterval);
                        this.talkingInterval = null;
                    }
                    
                    // Reset frame counters and test mode
                    this.currentTalkingFrame = 0;
                    this.fallbackTestMode = false;
                    
                    // Force return to idle state (smile) - clear any pending async texture loads first
                    // Set a flag to prevent frame animations from overwriting the idle state
                    const restoreIdleState = () => {
                        console.log('üîÑ Restoring idle state (smile)...');
                        // Force apply smile immediately
                        const img = document.querySelector(`img[id="${this.idleState.id.replace('#', '')}"]`);
                        if (img) {
                            this.recreateMaterial(img);
                            // Ensure geometry stays 1x1
                            this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                            console.log('‚úÖ Smile image restored via recreateMaterial');
                        } else {
                            // Fallback: use src but reset geometry immediately
                            this.orangePlane.setAttribute('src', this.idleState.id);
                            setTimeout(() => {
                                this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                            }, 10);
                            console.log('‚úÖ Smile image restored via setAttribute (geometry reset)');
                        }
                    this.setToIdleState();
                    };
                    
                    // Small delay to ensure frame animation interval is cleared
                    setTimeout(restoreIdleState, 100);
                }
                
                startThinkingAnimation() {
                    // Guard: if already running and interval exists, don't start again
                    if (this.isThinking && this.thinkingInterval) {
                        console.log('‚ö†Ô∏è Thinking animation already running, skipping duplicate start');
                        return;
                    }
                    
                    // Force stop any existing talking animation first
                    if (this.isTalking) {
                        console.log('‚ö†Ô∏è Stopping existing talking animation before starting thinking');
                        this.stopTalkingAnimation();
                    }
                    
                    // Clear any stale intervals - CRITICAL to prevent stacking
                    if (this.thinkingInterval) {
                        console.log('‚ö†Ô∏è Clearing existing thinking interval to prevent stacking');
                        clearInterval(this.thinkingInterval);
                        this.thinkingInterval = null;
                    }
                    
                    // Reset state flags
                    this.isThinking = true;
                    this.isIdle = false;
                    this.isTalking = false; // Ensure talking is false
                    
                    // Show image plane
                    const imageMesh = this.orangePlane.getObject3D('mesh');
                    if (imageMesh) {
                        imageMesh.visible = true;
                    }
                    
                    // Use frame-based animation if available, otherwise fall back to image-based
                    if (this.useFrameAnimations && this.thinkingFrames.length > 0) {
                        console.log(`üé¨ Starting frame-based thinking animation with ${this.thinkingFrames.length} frames`);
                        this.currentThinkingFrame = 0;
                        
                        // Start with first frame
                        this.applyTextureFromFrame(this.thinkingFrames[this.currentThinkingFrame]);
                        
                        // Loop forward through frames continuously
                        // 145 frames in 3 seconds = ~20.7ms per frame
                        const thinkingFrameInterval = Math.round(3000 / this.thinkingFrames.length);
                        console.log(`‚è±Ô∏è  Thinking animation: ${this.thinkingFrames.length} frames, interval=${thinkingFrameInterval}ms, target duration=3s`);
                        
                        // Use closure variables that persist but reset on loop
                        let thinkingFrameCount = 0;
                        let lastLoopTime = performance.now();
                        
                        this.thinkingInterval = setInterval(() => {
                            // Move to next frame
                            this.currentThinkingFrame++;
                            thinkingFrameCount++;
                            
                            // Check if we've reached the last frame
                            if (this.currentThinkingFrame >= this.thinkingFrames.length) {
                                // Check if we're in test mode (should stop after one cycle)
                                if (this.fallbackTestMode) {
                                    console.log(`‚úÖ Thinking animation completed (reached frame ${this.thinkingFrames.length - 1}) - test mode`);
                                    this.fallbackTestMode = false;
                                    this.stopThinkingAnimation();
                                    return;
                                }
                                // Normal operation: loop continuously - RESET timing to prevent acceleration
                                this.currentThinkingFrame = 0;
                                thinkingFrameCount = 0;
                                lastLoopTime = performance.now();
                                console.log('üîÑ Thinking animation looped, reset timing');
                            }
                            
                            // Apply the current frame
                            this.applyTextureFromFrame(this.thinkingFrames[this.currentThinkingFrame]);
                        }, thinkingFrameInterval);
                    } else {
                        // Fallback to image-based animation
                        console.log('ü§î Starting image-based thinking animation...');
                        this.currentThinkingState = 0;
                    
                    // Cycle through thinking states
                    this.thinkingInterval = setInterval(() => {
                        this.setToThinkingState(this.currentThinkingState);
                            this.currentThinkingState++;
                            
                            // Check if we've completed one full cycle
                            if (this.currentThinkingState >= this.thinkingStates.length) {
                                if (this.fallbackTestMode) {
                                    console.log('‚úÖ Fallback thinking animation completed one cycle');
                                    this.fallbackTestMode = false;
                                    this.stopThinkingAnimation();
                                    return;
                                }
                                // Normal operation: loop continuously
                                this.currentThinkingState = 0;
                            }
                        }, 100); // Fast animation, same speed as talking
                    }
                }
                
                stopThinkingAnimation() {
                    if (!this.isThinking) {
                        console.log('‚ö†Ô∏è No thinking animation running');
                        // Still reset test mode flag even if not running
                        this.fallbackTestMode = false;
                        return;
                    }
                    
                    this.isThinking = false;
                    console.log('üõë Stopping thinking animation, returning to idle');
                    
                    // Clear thinking interval immediately
                    if (this.thinkingInterval) {
                        clearInterval(this.thinkingInterval);
                        this.thinkingInterval = null;
                    }
                    
                    // Reset frame counters and test mode
                    this.currentThinkingFrame = 0;
                    this.fallbackTestMode = false;
                    
                    // Force return to idle state (smile) - clear any pending async texture loads first
                    const restoreIdleState = () => {
                        console.log('üîÑ Restoring idle state (smile)...');
                        const img = document.querySelector(`img[id="${this.idleState.id.replace('#', '')}"]`);
                        if (img) {
                            this.recreateMaterial(img);
                            // Ensure geometry stays 1x1
                            this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                            console.log('‚úÖ Smile image restored via recreateMaterial');
                        } else {
                            // Fallback: use src but reset geometry immediately
                            this.orangePlane.setAttribute('src', this.idleState.id);
                            setTimeout(() => {
                                this.orangePlane.setAttribute('geometry', { width: 1, height: 1 });
                            }, 10);
                            console.log('‚úÖ Smile image restored via setAttribute (geometry reset)');
                        }
                        this.setToIdleState();
                    };
                    
                    // Small delay to ensure frame animation interval is cleared
                    setTimeout(restoreIdleState, 100);
                    
                    console.log('‚úÖ Thinking animation stopped');
                }
                
                getStatus() {
                    return {
                        isTalking: this.isTalking,
                        isThinking: this.isThinking,
                        isIdle: this.isIdle,
                        currentThinkingState: this.currentThinkingState,
                        currentStateName: this.isIdle ? this.idleState.name : 
                                        this.isThinking ? this.thinkingStates[this.currentThinkingState].name :
                                        'talking-images',
                        planeSrc: this.orangePlane.getAttribute('src')
                    };
                }
            }
            
            // Initialize the animation module
            // Get orangePlane element (it's defined in initializeARSystem, but we need it here)
            const orangePlane = document.querySelector('#talking-orange-plane');
            let animationModule = null;
            if (!orangePlane) {
                console.error('‚ùå Orange plane element not found! Cannot initialize animation module.');
                // Skip initialization - animationModule will remain null
            } else {
                animationModule = new TalkingAnimationModule(orangePlane);
            }
            
            // Expose animation module globally for access from other functions
            window.animationModule = animationModule;
            
            // Test: Make orange plane visible immediately to verify it's not a visibility issue
            setTimeout(() => {
                if (orangePlane) {
                    const testMesh = orangePlane.getObject3D('mesh');
                    if (testMesh) {
                        testMesh.visible = true;
                        console.log('üß™ Test: Orange plane mesh forced visible for testing');
                        console.log('üß™ Mesh details:', {
                            visible: testMesh.visible,
                            position: testMesh.position,
                            material: testMesh.material ? 'exists' : 'missing'
                        });
                    }
                }
            }, 2000); // After 2 seconds, check if mesh exists and is visible
            
            // ========================================
            // THINKING ANIMATION CONTROLLER
            // Manages both visual animation and audio with different modes
            // ========================================
            class ThinkingAnimationController {
                constructor(animationModule, audioUrl) {
                    this.animationModule = animationModule;
                    this.audioUrl = audioUrl;
                    this.audio = null;
                    this.isPlaying = false;
                    this.loopMode = false; // false = single play, true = loop continuously
                    this.lastAnimationFrame = -1; // Track animation frame to detect loops
                    this.frameCheckInterval = null; // Interval to check for animation loops
                }
                
                // Start thinking animation
                start(options = {}) {
                    const { loop = false, playAudio = true } = options;
                    this.loopMode = loop;
                    
                    console.log(`ü§î Starting thinking animation (loop: ${loop}, audio: ${playAudio})`);
                    
                    // Set test mode based on loop mode
                    this.animationModule.fallbackTestMode = !loop;
                    
                    // Initialize frame tracking
                    this.lastAnimationFrame = -1;
                    
                    // Start frame monitoring immediately if in loop mode with audio
                    // This will detect when animation loops and restart audio accordingly
                    if (loop && playAudio) {
                        this.startFrameMonitoring();
                    }
                    
                    // Start visual animation immediately
                    this.animationModule.startThinkingAnimation();
                    
                    // Start audio if requested (with 1 second delay)
                    if (playAudio) {
                        setTimeout(() => {
                            this.playAudioOnce(); // Play once per cycle
                            // Initialize frame tracking after audio starts
                            this.lastAnimationFrame = this.animationModule.currentThinkingFrame || 0;
                        }, 1000); // 1 second delay
                    }
                }
                
                // Monitor animation frames to detect when animation loops (resets to 0)
                startFrameMonitoring() {
                    // Clear existing interval
                    if (this.frameCheckInterval) {
                        clearInterval(this.frameCheckInterval);
                    }
                    
                    console.log('üëÅÔ∏è Starting frame monitoring to detect animation loops');
                    
                    // Check every 50ms for frame resets (indicates animation looped)
                    this.frameCheckInterval = setInterval(() => {
                        if (!this.animationModule.isThinking) {
                            // Animation stopped, stop monitoring
                            this.stopFrameMonitoring();
                            return;
                        }
                        
                        const currentFrame = this.animationModule.currentThinkingFrame || 0;
                        
                        // Only check for loop if we have a valid last frame
                        if (this.lastAnimationFrame >= 0) {
                            // Detect when animation loops: frame goes from near end (>= 140) back to start (0-10)
                            // This indicates the animation completed one cycle and restarted
                            if (currentFrame <= 10 && this.lastAnimationFrame >= 140 && this.loopMode && !this.isPlaying) {
                                console.log(`üîÑ Animation looped detected (frame ${this.lastAnimationFrame} -> ${currentFrame}), restarting audio`);
                                this.playAudioOnce();
                            }
                        }
                        
                        // Update last frame tracker (only update if we're progressing forward or looping)
                        if (currentFrame > this.lastAnimationFrame || (currentFrame <= 10 && this.lastAnimationFrame >= 140)) {
                            this.lastAnimationFrame = currentFrame;
                        }
                    }, 50); // Check more frequently for better detection
                }
                
                // Stop frame monitoring
                stopFrameMonitoring() {
                    if (this.frameCheckInterval) {
                        clearInterval(this.frameCheckInterval);
                        this.frameCheckInterval = null;
                    }
                }
                
                // Stop thinking animation
                stop() {
                    console.log('üõë Stopping thinking animation and audio...');
                    
                    // Clear frame check interval
                    if (this.frameCheckInterval) {
                        clearInterval(this.frameCheckInterval);
                        this.frameCheckInterval = null;
                    }
                    
                    this.animationModule.stopThinkingAnimation();
                    this.stopAudio();
                    this.lastAnimationFrame = -1;
                }
                
                // Play audio once (not looping forever)
                playAudioOnce() {
                    // Stop existing audio if any
                    if (this.audio) {
                        try {
                            this.audio.pause();
                            this.audio.currentTime = 0;
                            this.audio = null;
                        } catch (e) {
                            console.warn('‚ö†Ô∏è Error stopping existing audio:', e);
                        }
                    }
                    
                    if (!this.audioUrl) {
                        console.warn('‚ö†Ô∏è No thinking audio URL configured');
                        return;
                    }
                    
                    console.log('üéµ Starting thinking audio (one play per animation cycle)...', {
                        audioUrl: this.audioUrl,
                        timestamp: new Date().toISOString()
                    });
                    
                    try {
                        this.audio = new Audio(this.audioUrl);
                        this.audio.loop = false; // Don't loop forever
                        this.audio.volume = 1.0; // Set volume to maximum
                        this.audio.muted = false; // Ensure not muted
                        
                        console.log('üîä [AUDIO] Audio object created', {
                            volume: this.audio.volume,
                            muted: this.audio.muted,
                            audioUrl: this.audioUrl
                        });
                        
                        // Log when audio is loaded
                        this.audio.onloadeddata = () => {
                            console.log('‚úÖ Thinking audio data loaded', {
                                duration: this.audio.duration ? this.audio.duration.toFixed(2) + 's' : 'unknown',
                                volume: this.audio.volume,
                                muted: this.audio.muted
                            });
                        };
                        
                        // Log when audio can play
                        this.audio.oncanplay = () => {
                            console.log('‚úÖ Thinking audio can play');
                        };
                        
                        // When audio ends, just mark it as done - don't restart automatically
                        this.audio.onended = () => {
                            console.log('üîö Thinking audio finished playing');
                            this.audio = null;
                            this.isPlaying = false;
                            // Don't restart here - wait for animation loop detection
                        };
                        
                        // Log when audio starts
                        this.audio.onplay = () => {
                            console.log('‚ñ∂Ô∏è Thinking audio started playing');
                            this.isPlaying = true;
                        };
                        
                        // Handle errors with more detail
                        this.audio.onerror = (e) => {
                            console.error('‚ùå Thinking audio error:', {
                                error: e,
                                code: this.audio?.error?.code,
                                message: this.audio?.error?.message,
                                audioUrl: this.audioUrl
                            });
                            if (this.audio?.error) {
                                const errorCodes = {
                                    1: 'MEDIA_ERR_ABORTED',
                                    2: 'MEDIA_ERR_NETWORK',
                                    3: 'MEDIA_ERR_DECODE',
                                    4: 'MEDIA_ERR_SRC_NOT_SUPPORTED'
                                };
                                console.error(`   Error code: ${this.audio.error.code} (${errorCodes[this.audio.error.code] || 'UNKNOWN'})`);
                            }
                            this.audio = null;
                            this.isPlaying = false;
                        };
                        
                        // Start playing
                        const playPromise = this.audio.play();
                        if (playPromise !== undefined) {
                            playPromise
                                .then(() => {
                                    console.log('‚úÖ Thinking audio playback started successfully');
                                })
                                .catch(err => {
                                    console.error('‚ùå Failed to play thinking audio:', {
                                        error: err,
                                        name: err.name,
                                        message: err.message,
                                        audioUrl: this.audioUrl
                                    });
                                    if (err.name === 'NotAllowedError') {
                                        console.warn('   Autoplay was blocked by browser. User interaction required.');
                                    } else if (err.name === 'NotSupportedError') {
                                        console.warn('   Audio format not supported by browser.');
                                    }
                                    this.audio = null;
                                    this.isPlaying = false;
                                });
                        } else {
                            console.warn('‚ö†Ô∏è Audio.play() returned undefined - browser may not support promises');
                        }
                    } catch (error) {
                        console.error('‚ùå Error creating audio object:', {
                            error: error,
                            audioUrl: this.audioUrl
                        });
                        this.audio = null;
                        this.isPlaying = false;
                    }
                }
                
                // Check if animation has looped (frame reset to 0) and restart audio if needed
                checkAnimationLoop() {
                    if (!this.loopMode || !this.animationModule.isThinking) {
                        return;
                    }
                    
                    const currentFrame = this.animationModule.currentThinkingFrame;
                    
                    // Detect animation loop: frame went from last frame (or near end) back to 0
                    // or frame is 0 and we were tracking a higher frame before
                    if (currentFrame === 0 && this.lastAnimationFrame > 100) {
                        // Animation looped! Restart audio
                        console.log('üîÑ Animation looped, restarting thinking audio');
                        this.playAudioOnce();
                    }
                    
                    // Update last frame tracker
                    this.lastAnimationFrame = currentFrame;
                }
                
                // Stop audio
                stopAudio() {
                    if (this.audio) {
                        console.log('üîá Stopping thinking audio...');
                        this.audio.pause();
                        this.audio.currentTime = 0;
                        this.audio = null;
                        this.isPlaying = false;
                        console.log('‚úÖ Thinking audio stopped');
                    }
                }
            }
            
            // ========================================
            // TALKING ANIMATION CONTROLLER
            // Manages visual animation with different modes
            // ========================================
            class TalkingAnimationController {
                constructor(animationModule, introAudioUrl = null) {
                    this.animationModule = animationModule;
                    this.introAudioUrl = introAudioUrl;
                    this.introAudio = null;
                }
                
                // Start talking animation
                start(options = {}) {
                    const { loop = false, playIntro = false } = options;
                    // Set test mode to stop after one cycle if not looping
                    this.animationModule.fallbackTestMode = !loop;
                    
                    console.log(`üó£Ô∏è Starting talking animation (loop: ${loop}, intro: ${playIntro})`);
                    
                    // If intro audio is requested, play it first then start animation
                    if (playIntro && this.introAudioUrl) {
                        this.playIntroAudio();
                    } else {
                        // Start visual animation immediately
                        this.animationModule.startTalkingAnimation();
                    }
                }
                
                // Play intro audio
                playIntroAudio() {
                    if (!this.introAudioUrl) {
                        console.warn('‚ö†Ô∏è No intro audio URL configured');
                        // Fallback to starting animation without intro
                        this.animationModule.startTalkingAnimation();
                        return;
                    }
                    
                    console.log('üéµ Playing intro audio...');
                    
                    // Stop any existing intro audio
                    if (this.introAudio) {
                        this.introAudio.pause();
                        this.introAudio = null;
                    }
                    
                    this.introAudio = new Audio(this.introAudioUrl);
                    this.introAudio.volume = 1.0; // Set volume to maximum
                    this.introAudio.muted = false; // Ensure not muted
                    
                    console.log('üîä [INTRO AUDIO] Audio object created', {
                        volume: this.introAudio.volume,
                        muted: this.introAudio.muted,
                        audioUrl: this.introAudioUrl
                    });
                    
                    // When intro audio starts, start the animation
                    this.introAudio.onplay = () => {
                        console.log('‚ñ∂Ô∏è Intro audio started, starting talking animation');
                        this.animationModule.startTalkingAnimation();
                    };
                    
                    // When intro audio ends, animation continues
                    this.introAudio.onended = () => {
                        console.log('üîö Intro audio finished');
                        this.introAudio = null;
                    };
                    
                    // Handle errors
                    this.introAudio.onerror = (e) => {
                        console.warn('‚ö†Ô∏è Intro audio error:', e);
                        this.introAudio = null;
                        // Fallback to starting animation without intro
                        this.animationModule.startTalkingAnimation();
                    };
                    
                    // Start playing
                    const playPromise = this.introAudio.play();
                    if (playPromise !== undefined) {
                        playPromise
                            .then(() => {
                                console.log('‚úÖ Intro audio playback started');
                            })
                            .catch(err => {
                                console.warn('‚ö†Ô∏è Failed to play intro audio:', err);
                                this.introAudio = null;
                                // Fallback to starting animation without intro
                                this.animationModule.startTalkingAnimation();
                            });
                    }
                }
                
                // Stop talking animation
                stop() {
                    console.log('üõë Stopping talking animation...');
                    
                    // Stop intro audio if playing
                    if (this.introAudio) {
                        this.introAudio.pause();
                        this.introAudio.currentTime = 0;
                        this.introAudio = null;
                    }
                    
                    this.animationModule.stopTalkingAnimation();
                }
            }
            
            // Get audio URLs from current target media or use defaults
            function getAudioUrl(filename) {
                if (currentTargetMedia) {
                    // First try to find exact match
                    let audioFile = currentTargetMedia.find(m => m.filename === filename);
                    if (audioFile) return audioFile.url;
                    
                    // Then try partial match
                    audioFile = currentTargetMedia.find(m => m.filename.includes(filename) || filename.includes(m.filename));
                    if (audioFile) return audioFile.url;
                    
                    // Try to construct URL from current target and video directory (project-based)
                    if (currentTarget && currentTarget.userId && currentTarget.projectName) {
                        // Audio files are in video directories
                        if (filename.includes('thinking')) {
                            return `/api/users/${currentTarget.userId}/${currentTarget.projectName}/media/videos/talking-orange-thinking-animation/thinking-hmm.mp3`;
                        } else if (filename.includes('intro-es')) {
                            return `/api/users/${currentTarget.userId}/${currentTarget.projectName}/media/videos/talking-orange-talking-animation/talking-intro-es.mp3`;
                        } else if (filename.includes('intro') || filename.includes('talking')) {
                            return `/api/users/${currentTarget.userId}/${currentTarget.projectName}/media/videos/talking-orange-talking-animation/talking-intro.mp3`;
                        }
                    } else if (currentTarget && currentTarget.userId) {
                        // Fallback to old structure if no projectName
                        if (filename.includes('thinking')) {
                            return `/api/users/${currentTarget.userId}/media/videos/talking-orange-thinking-animation/thinking-hmm.mp3`;
                        } else if (filename.includes('intro-es')) {
                            return `/api/users/${currentTarget.userId}/media/videos/talking-orange-talking-animation/talking-intro-es.mp3`;
                        } else if (filename.includes('intro') || filename.includes('talking')) {
                            return `/api/users/${currentTarget.userId}/media/videos/talking-orange-talking-animation/talking-intro.mp3`;
                        }
                    }
                }
                // Final fallback to default frontend paths (shouldn't happen in normal operation)
                console.warn(`‚ö†Ô∏è [AUDIO] No target context, using fallback path for ${filename}`);
                if (filename.includes('thinking')) {
                    return './media/videos/talking-orange-thinking-animation/thinking-hmm.mp3';
                } else if (filename.includes('intro-es')) {
                    return './media/videos/talking-orange-talking-animation/talking-intro-es.mp3';
                } else {
                    return './media/videos/talking-orange-talking-animation/talking-intro.mp3';
                }
            }
            
            // Initialize animation controllers (only if animationModule was created)
            let thinkingController = null;
            let talkingController = null;
            
            if (animationModule) {
                thinkingController = new ThinkingAnimationController(
                    animationModule,
                    getAudioUrl('thinking-hmm.mp3')
                );
                // Talking controller will be updated based on language
                talkingController = new TalkingAnimationController(
                    animationModule,
                    getAudioUrl('talking-intro.mp3')
                );
            } else {
                console.warn('‚ö†Ô∏è Animation module not initialized - controllers will not be available');
            }
            
            // Make controllers available globally for test functions
            window.thinkingController = thinkingController;
            window.talkingController = talkingController;
            
            // Function to update talking controller intro audio based on language
            function updateTalkingControllerLanguage(lang) {
                if (!animationModule) {
                    console.warn('‚ö†Ô∏è Cannot update talking controller language - animation module not initialized');
                    return;
                }
                const introAudioUrl = lang === 'es' 
                    ? getAudioUrl('talking-intro-es.mp3')
                    : getAudioUrl('talking-intro.mp3');
                if (introAudioUrl) {
                    talkingController = new TalkingAnimationController(
                        animationModule,
                        introAudioUrl
                    );
                    window.talkingController = talkingController; // Update global reference
                    console.log(`üîÑ Updated talking controller with ${lang} audio: ${introAudioUrl}`);
                } else {
                    console.warn('‚ö†Ô∏è Could not get audio URL for talking controller');
                }
            }
            
            // Legacy audio functions (deprecated - use controllers instead)
            let thinkingAudio = null;
            const thinkingAudioUrl = getAudioUrl('thinking-hmm.mp3');
            
            // Play thinking audio in a loop (using pre-generated static file)
            function playThinkingAudioLoop() {
                console.log('üéµ Attempting to start thinking audio from:', thinkingAudioUrl);
                
                // Stop existing audio if any
                if (thinkingAudio) {
                    console.log('üõë Stopping existing thinking audio');
                    thinkingAudio.pause();
                    thinkingAudio = null;
                }
                
                thinkingAudio = new Audio(thinkingAudioUrl);
                
                // Set up event handlers before playing
                thinkingAudio.loop = true;
                
                // Log when audio is loaded
                thinkingAudio.onloadeddata = function() {
                    console.log('‚úÖ Thinking audio loaded and ready to play');
                };
                
                // Log when audio starts playing
                thinkingAudio.onplay = function() {
                    console.log('‚ñ∂Ô∏è Thinking audio started playing');
                };
                
                // Restart on end if loop didn't work (some browsers don't support loop property well)
                thinkingAudio.onended = function() {
                    console.log('üîÑ Thinking audio ended, restarting...');
                    if (animationModule.isThinking) {
                        thinkingAudio.currentTime = 0;
                        thinkingAudio.play().catch(err => {
                            console.warn('‚ö†Ô∏è Thinking audio play error on restart:', err);
                        });
                    }
                };
                
                // Handle errors gracefully (file might not exist, that's okay)
                thinkingAudio.onerror = function(e) {
                    console.warn('‚ö†Ô∏è Thinking audio error:', e);
                    console.warn('   File may not exist. Run: python3 backend/gen/generate_thinking_audio.py');
                    thinkingAudio = null;
                };
                
                // Start playing with promise to catch autoplay issues
                const playPromise = thinkingAudio.play();
                
                if (playPromise !== undefined) {
                    playPromise
                        .then(() => {
                            console.log('‚úÖ Thinking audio playback started successfully');
                        })
                        .catch(err => {
                            console.warn('‚ö†Ô∏è Failed to play thinking audio (autoplay may be blocked):', err);
                            console.warn('   Audio will play when user interacts with the page');
                            // Not critical - animation will continue without audio
                        });
                }
                
                console.log('üîä Thinking audio setup complete');
            }
            
            // Stop thinking audio
            function stopThinkingAudio() {
                if (thinkingAudio) {
                    console.log('üîá Stopping thinking audio...');
                    thinkingAudio.pause();
                    thinkingAudio.currentTime = 0;
                    thinkingAudio = null;
                    console.log('‚úÖ Thinking audio stopped');
                } else {
                    console.log('‚ÑπÔ∏è No thinking audio to stop');
                }
            }
            
            // Expose functions for external control (conversation flow - loops)
            function startTalkingAnimation() {
                if (talkingController) {
                    talkingController.start({ loop: true });
                } else {
                    console.warn('‚ö†Ô∏è Talking controller not available');
                }
            }
            
            // Global audio object to track current playback
            let currentAudio = null;
            
            function stopTalkingAnimation() {
                if (talkingController) {
                    talkingController.stop();
                } else {
                    console.warn('‚ö†Ô∏è Talking controller not available');
                }
            }
            
            function startThinkingAnimation() {
                // Conversation mode: loop animation, play audio once per cycle
                if (thinkingController) {
                    thinkingController.start({ loop: true, playAudio: true });
                } else {
                    console.warn('‚ö†Ô∏è Thinking controller not available');
                }
            }
            
            function stopThinkingAnimation() {
                if (thinkingController) {
                    thinkingController.stop();
                } else {
                    console.warn('‚ö†Ô∏è Thinking controller not available');
                }
            }
            
            // Stop audio playback and animation
            function stopAudio() {
                console.log('‚èπÔ∏è [STOP] User requested to stop audio playback');
                
                // Stop current audio if playing
                if (currentAudio) {
                    try {
                        currentAudio.pause();
                        currentAudio.currentTime = 0;
                        console.log('‚úÖ [STOP] Audio playback stopped');
                    } catch (error) {
                        console.warn('‚ö†Ô∏è [STOP] Error stopping audio:', error);
                    }
                    currentAudio = null;
                }
                
                // Stop talking animation
                stopTalkingAnimation();
                
                // Hide stop button
                const stopBtn = document.getElementById('stop-audio-btn');
                if (stopBtn) {
                    stopBtn.style.display = 'none';
                }
                
                console.log('‚úÖ [STOP] All playback stopped, ready for new question');
            }
            
            // Voice recording and processing system
            // Declare variables first to avoid temporal dead zone issues
            let mediaRecorder = null;
            let audioChunks = [];
            let isRecording = false;
            let recordingTimer = null;
            let recordingStartTime = null;
            
            // Make askQuestion available on window immediately
            window.askQuestion = async function askQuestion() {
                if (isRecording) {
                    console.log('Stopping recording...');
                    stopRecording();
                    return;
                }
                
                try {
                    console.log('üé§ Starting voice recording...');
                    
                    // Request microphone access
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    
                    // Set up MediaRecorder
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];
                    
                    mediaRecorder.ondataavailable = function(event) {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                            console.log(`üì¶ Collected audio chunk: ${event.data.size} bytes`);
                        }
                    };
                    
                    mediaRecorder.onstop = async function() {
                        const recordingDuration = recordingStartTime ? (Date.now() - recordingStartTime) : 0;
                        console.log('üîä [RECORDING STOPPED] Processing audio...', {
                            duration: recordingDuration + 'ms (' + (recordingDuration / 1000).toFixed(2) + 's)',
                            chunks: audioChunks.length,
                            timestamp: new Date().toISOString()
                        });
                        
                        // Check if we actually recorded any audio
                        if (audioChunks.length === 0 || audioChunks.every(chunk => chunk.size === 0)) {
                            console.error('‚ùå [RECORDING ERROR] No audio data recorded - microphone may be off or not working');
                            stopThinkingAnimation();
                            alert('‚ö†Ô∏è No audio recorded. Please check your microphone and try again.');
                            return;
                        }
                        
                        const blobStartTime = performance.now();
                        // Create audio blob
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        const blobDuration = (performance.now() - blobStartTime).toFixed(0);
                        console.log(`üìä [AUDIO BLOB] Created in ${blobDuration}ms`, {
                            size: audioBlob.size + ' bytes',
                            sizeKB: (audioBlob.size / 1024).toFixed(2) + ' KB',
                            chunks: audioChunks.length
                        });
                        
                        // Validate audio blob size
                        if (audioBlob.size < 100) {
                            console.error('‚ùå [RECORDING ERROR] Audio blob too small - microphone may not be working');
                            stopThinkingAnimation();
                            alert('‚ö†Ô∏è Audio recording is too short or empty. Please check your microphone and try again.');
                            return;
                        }
                        
                        // Convert to base64
                        const base64StartTime = performance.now();
                        const reader = new FileReader();
                        reader.onloadend = async function() {
                            const base64Duration = (performance.now() - base64StartTime).toFixed(0);
                            const base64Audio = reader.result.split(',')[1]; // Remove data:audio/webm;base64, prefix
                            console.log(`üì§ [BASE64 CONVERSION] Completed in ${base64Duration}ms`, {
                                base64Length: base64Audio.length + ' characters',
                                estimatedSize: (base64Audio.length * 3 / 4).toFixed(0) + ' bytes',
                                timestamp: new Date().toISOString()
                            });
                            
                            // Send to backend for processing
                            await processVoiceInput(base64Audio);
                        };
                        reader.onerror = function(error) {
                            console.error('‚ùå [BASE64 ERROR] FileReader error:', error);
                        };
                        reader.readAsDataURL(audioBlob);
                        
                        // Stop all tracks
                        stream.getTracks().forEach(track => track.stop());
                    };
                    
                    // Start recording with timeslice to ensure we capture all data
                    mediaRecorder.start(1000); // Request data every 1 second
                    isRecording = true;
                    recordingStartTime = Date.now();
                    
                    // Show recording indicator
                    const button = document.getElementById('ask-question-btn');
                    button.textContent = currentLanguage === 'es' ? 'Detener Grabaci√≥n (0s)' : 'Stop Recording (0s)';
                    button.style.background = '#f44336';
                    
                    // Update timer every second
                    recordingTimer = setInterval(() => {
                        if (isRecording) {
                            const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
                            button.textContent = currentLanguage === 'es' ? `Detener Grabaci√≥n (${elapsed}s)` : `Stop Recording (${elapsed}s)`;
                            
                            // Auto-stop after 1 minute (60 seconds)
                            if (elapsed >= 60) {
                                console.log('‚è∞ Auto-stopping recording after 1 minute');
                                stopRecording();
                            }
                        }
                    }, 1000);
                    
                } catch (error) {
                    console.error('‚ùå Error accessing microphone:', error);
                    alert('Error accessing microphone. Please check permissions.');
                }
            }
            
            function stopRecording() {
                if (mediaRecorder && isRecording) {
                    console.log('üõë Stopping recording...');
                    isRecording = false;
                    
                    // Clear the timer
                    if (recordingTimer) {
                        clearInterval(recordingTimer);
                        recordingTimer = null;
                    }
                    
                    // Request final data before stopping
                    mediaRecorder.requestData();
                    
                    // Stop the recorder (this will trigger onstop)
                    mediaRecorder.stop();
                    
                    // Reset button
                    const button = document.getElementById('ask-question-btn');
                    updateButtonText(); // Use the dynamic text function
                    button.style.background = '#2196F3';
                    
                    // Start thinking animation while processing
                    console.log('ü§î Starting thinking animation...');
                    startThinkingAnimation();
                }
            }
            
            async function processVoiceInput(audioData) {
                const requestStartTime = performance.now();
                const requestTimestamp = new Date().toISOString();
                const sessionId = 'web_session_' + Date.now();
                
                // Check Whisper device status before processing
                let whisperDevice = 'unknown';
                try {
                    const healthResponse = await fetch('/api/health');
                    const healthData = await healthResponse.json();
                    const deviceInfo = healthData.whisper_device || {};
                    whisperDevice = deviceInfo.device || 'unknown';
                    const useFp16 = deviceInfo.use_fp16 || false;
                    const modelName = deviceInfo.model_name || 'unknown';
                    
                    if (whisperDevice === 'cuda') {
                        console.log(`üöÄ [WHISPER DEVICE] GPU (CUDA) - Fast processing expected`, {
                            device: whisperDevice,
                            fp16: useFp16,
                            model: modelName
                        });
                    } else if (whisperDevice === 'cpu') {
                        console.warn(`‚ö†Ô∏è [WHISPER DEVICE] CPU - Processing may be slower`, {
                            device: whisperDevice,
                            fp16: useFp16,
                            model: modelName
                        });
                    }
                } catch (error) {
                    console.warn('‚ö†Ô∏è Could not check Whisper device status:', error);
                }
                
                try {
                    console.log('üì§ [API REQUEST START] Sending audio to backend...', {
                        timestamp: requestTimestamp,
                        sessionId: sessionId,
                        audioDataLength: audioData.length,
                        audioDataSize: (audioData.length * 3 / 4).toFixed(0) + ' bytes (approx)',
                        language: currentLanguage,
                        whisperDevice: whisperDevice
                    });
                    
                    const fetchStartTime = performance.now();
                    
                    // Add timeout to prevent hanging
                    const timeoutMs = 120000; // 2 minutes timeout
                    const controller = new AbortController();
                    const timeoutId = setTimeout(() => {
                        controller.abort();
                        console.error('‚ùå [API TIMEOUT] Request timed out after ' + timeoutMs + 'ms');
                    }, timeoutMs);
                    
                    let response;
                    try {
                        response = await fetch('/api/speech/process', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                            },
                            body: JSON.stringify({
                                audioData: audioData,
                                sessionId: sessionId,
                                language: currentLanguage,
                                ttsVoice: 'default',
                                ttsEngine: 'auto'
                            }),
                            signal: controller.signal
                        });
                        clearTimeout(timeoutId);
                    } catch (fetchError) {
                        clearTimeout(timeoutId);
                        if (fetchError.name === 'AbortError') {
                            throw new Error('Request timed out after ' + timeoutMs + 'ms - backend may be unresponsive');
                        }
                        throw new Error('Network error: ' + fetchError.message);
                    }
                    
                    const fetchEndTime = performance.now();
                    const fetchDuration = (fetchEndTime - fetchStartTime).toFixed(0);
                    console.log(`üì° [API FETCH COMPLETE] Response received in ${fetchDuration}ms`, {
                        status: response.status,
                        statusText: response.statusText,
                        headers: Object.fromEntries(response.headers.entries())
                    });
                    
                    if (!response.ok) {
                        let errorMessage = `HTTP error! status: ${response.status}`;
                        let errorDetails = null;
                        
                        // Clone response to read it multiple times if needed
                        const responseClone = response.clone();
                        
                        try {
                            // Try to parse as JSON first (Flask returns JSON errors)
                            const errorData = await response.json();
                            errorMessage = errorData.error || errorMessage;
                            errorDetails = errorData;
                            console.error('‚ùå [API ERROR] HTTP error response (JSON):', {
                                status: response.status,
                                statusText: response.statusText,
                                error: errorMessage,
                                details: errorDetails,
                                fetchDuration: fetchDuration + 'ms'
                            });
                        } catch (jsonError) {
                            // If JSON parsing fails, try to get text from clone
                            try {
                                const errorText = await responseClone.text();
                                console.error('‚ùå [API ERROR] HTTP error response (text):', {
                                    status: response.status,
                                    statusText: response.statusText,
                                    body: errorText.substring(0, 500), // First 500 chars
                                    fetchDuration: fetchDuration + 'ms'
                                });
                                // Try to extract error message from HTML if it's an HTML error page
                                const errorMatch = errorText.match(/KeyError: '([^']+)'/);
                                if (errorMatch) {
                                    errorMessage = `KeyError: Missing key '${errorMatch[1]}' in request data`;
                                } else {
                                    errorMessage = errorText.substring(0, 200) || errorMessage;
                                }
                            } catch (textError) {
                                console.error('‚ùå [API ERROR] Could not read error response:', textError);
                            }
                        }
                        
                        throw new Error(errorMessage);
                    }
                    
                    const parseStartTime = performance.now();
                    const result = await response.json();
                    const parseEndTime = performance.now();
                    const parseDuration = (parseEndTime - parseStartTime).toFixed(0);
                    
                    const totalDuration = (performance.now() - requestStartTime).toFixed(0);
                    console.log(`‚úÖ [API RESPONSE PARSED] Voice processing complete in ${totalDuration}ms total`, {
                        fetchDuration: fetchDuration + 'ms',
                        parseDuration: parseDuration + 'ms',
                        result: result,
                        hasAudioUrl: !!result.audioUrl,
                        hasTranscription: !!result.transcription,
                        hasResponse: !!result.response
                    });
                    
                    // Log detailed timing breakdown
                    console.log('‚è±Ô∏è [TIMING BREAKDOWN]', {
                        totalTime: totalDuration + 'ms',
                        fetchTime: fetchDuration + 'ms',
                        parseTime: parseDuration + 'ms',
                        timestamp: new Date().toISOString()
                    });
                    
                    // Play the audio response
                    if (result.audioUrl) {
                        const audioStartTime = performance.now();
                        console.log('üîä [AUDIO PLAYBACK START] Starting audio playback...', {
                            audioUrl: result.audioUrl,
                            timestamp: new Date().toISOString()
                        });
                        await playAudioResponse(result.audioUrl);
                        const audioEndTime = performance.now();
                        console.log(`üîä [AUDIO PLAYBACK INITIATED] Audio playback started in ${(audioEndTime - audioStartTime).toFixed(0)}ms`);
                    } else {
                        console.warn('‚ö†Ô∏è [AUDIO MISSING] No audioUrl in response');
                    }
                    
                    // Show transcription and response
                    console.log('üìù [TRANSCRIPTION]', result.transcription || '(none)');
                    console.log('üí¨ [RESPONSE TEXT]', result.response || '(none)');
                    
                } catch (error) {
                    const errorDuration = (performance.now() - requestStartTime).toFixed(0);
                    console.error('‚ùå [API ERROR] Voice processing failed after ' + errorDuration + 'ms', {
                        error: error,
                        errorMessage: error.message,
                        errorName: error.name,
                        errorStack: error.stack,
                        timestamp: new Date().toISOString(),
                        sessionId: sessionId
                    });
                    
                    // Stop thinking animation on error
                    if (window.talkingAnimationModule) {
                        window.talkingAnimationModule.stopThinkingAnimation();
                    }
                    alert('Error processing voice input: ' + error.message);
                }
            }
            
            async function playAudioResponse(audioUrl) {
                const audioStartTime = performance.now();
                const audioTimestamp = new Date().toISOString();
                
                try {
                    console.log('üîä [AUDIO] Starting audio playback...', {
                        audioUrl: audioUrl,
                        timestamp: audioTimestamp
                    });
                    
                    // Stop any existing audio first
                    if (currentAudio) {
                        try {
                            currentAudio.pause();
                            currentAudio.currentTime = 0;
                            console.log('üîÑ [AUDIO] Stopped previous audio playback');
                        } catch (error) {
                            console.warn('‚ö†Ô∏è [AUDIO] Error stopping previous audio:', error);
                        }
                    }
                    
                    // Stop thinking animation and start talking animation
                    const animStartTime = performance.now();
                    stopThinkingAnimation();
                    startTalkingAnimation();
                    const animDuration = (performance.now() - animStartTime).toFixed(0);
                    console.log(`üé≠ [ANIMATION] Switched to talking animation in ${animDuration}ms`);
                    
                    // Show stop button
                    const stopBtn = document.getElementById('stop-audio-btn');
                    if (stopBtn) {
                        stopBtn.style.display = 'block';
                    }
                    
                    const audioLoadStartTime = performance.now();
                    
                    // Validate audio URL
                    if (!audioUrl) {
                        throw new Error('Audio URL is empty or undefined');
                    }
                    
                    console.log('üîä [AUDIO] Creating audio object...', {
                        audioUrl: audioUrl,
                        urlType: typeof audioUrl
                    });
                    
                    const audio = new Audio(audioUrl);
                    audio.volume = 1.0; // Set volume to maximum
                    audio.muted = false; // Ensure not muted
                    
                    console.log('üîä [AUDIO] Audio object created', {
                        volume: audio.volume,
                        muted: audio.muted,
                        audioUrl: audioUrl
                    });
                    
                    // Store audio globally so we can stop it
                    currentAudio = audio;
                    
                    // Track audio loading with error handling
                    audio.addEventListener('loadstart', () => {
                        console.log('üì• [AUDIO] Load started', {
                            audioUrl: audioUrl,
                            timeSinceRequest: (performance.now() - audioLoadStartTime).toFixed(0) + 'ms'
                        });
                    });
                    
                    // Track errors during loading
                    audio.addEventListener('error', (e) => {
                        console.error('‚ùå [AUDIO] Error loading audio:', {
                            error: e,
                            code: audio.error?.code,
                            message: audio.error?.message,
                            audioUrl: audioUrl
                        });
                        if (audio.error) {
                            const errorCodes = {
                                1: 'MEDIA_ERR_ABORTED',
                                2: 'MEDIA_ERR_NETWORK',
                                3: 'MEDIA_ERR_DECODE',
                                4: 'MEDIA_ERR_SRC_NOT_SUPPORTED'
                            };
                            console.error(`   Error code: ${audio.error.code} (${errorCodes[audio.error.code] || 'UNKNOWN'})`);
                        }
                    });
                    
                    audio.addEventListener('loadeddata', () => {
                        console.log('‚úÖ [AUDIO] Data loaded', {
                            duration: audio.duration ? audio.duration.toFixed(2) + 's' : 'unknown',
                            timeSinceRequest: (performance.now() - audioLoadStartTime).toFixed(0) + 'ms'
                        });
                    });
                    
                    audio.addEventListener('canplay', () => {
                        console.log('‚ñ∂Ô∏è [AUDIO] Can play', {
                            timeSinceRequest: (performance.now() - audioLoadStartTime).toFixed(0) + 'ms'
                        });
                    });
                    
                    // Stop animation when audio ends
                    audio.onended = function() {
                        const totalDuration = (performance.now() - audioStartTime).toFixed(0);
                        console.log(`‚úÖ [AUDIO] Playback completed in ${totalDuration}ms, stopping talking animation`, {
                            timestamp: new Date().toISOString()
                        });
                        stopTalkingAnimation();
                        
                        // Clear audio reference and hide stop button
                        currentAudio = null;
                        const stopBtn = document.getElementById('stop-audio-btn');
                        if (stopBtn) {
                            stopBtn.style.display = 'none';
                        }
                    };
                    
                    // Also handle errors
                    audio.onerror = function(e) {
                        const errorDuration = (performance.now() - audioStartTime).toFixed(0);
                        console.error(`‚ùå [AUDIO ERROR] Playback error after ${errorDuration}ms`, {
                            error: e,
                            audioUrl: audioUrl,
                            timestamp: new Date().toISOString()
                        });
                        stopTalkingAnimation();
                        
                        // Clear audio reference and hide stop button
                        currentAudio = null;
                        const stopBtn = document.getElementById('stop-audio-btn');
                        if (stopBtn) {
                            stopBtn.style.display = 'none';
                        }
                    };
                    
                    const playStartTime = performance.now();
                    await audio.play();
                    const playDuration = (performance.now() - playStartTime).toFixed(0);
                    console.log(`‚ñ∂Ô∏è [AUDIO] Play started in ${playDuration}ms`, {
                        audioUrl: audioUrl,
                        timestamp: new Date().toISOString()
                    });
                    
                } catch (error) {
                    const errorDuration = (performance.now() - audioStartTime).toFixed(0);
                    console.error(`‚ùå [AUDIO ERROR] Playback failed after ${errorDuration}ms`, {
                        error: error,
                        errorMessage: error.message,
                        audioUrl: audioUrl,
                        timestamp: new Date().toISOString()
                    });
                    // Stop animation on error
                    stopTalkingAnimation();
                    
                    // Clear audio reference and hide stop button
                    currentAudio = null;
                    const stopBtn = document.getElementById('stop-audio-btn');
                    if (stopBtn) {
                        stopBtn.style.display = 'none';
                    }
                }
            }
            
            // Debug function
            function debugAnimation() {
                console.log('üîç Animation Debug Report');
                console.log('========================');
                console.log('Animation Module Status:', animationModule.getStatus());
                console.log('Orange Plane Element:', orangePlane);
                console.log('Orange Plane Attributes:', {
                    src: orangePlane.getAttribute('src'),
                    position: orangePlane.getAttribute('position'),
                    rotation: orangePlane.getAttribute('rotation'),
                    material: orangePlane.getAttribute('material')
                });
                
                // Manual testing - only when debug button is clicked
                console.log('üß™ Manual animation state testing...');
                console.log('Testing idle state (smile)');
                animationModule.setToIdleState();
                
                setTimeout(() => {
                    console.log('Testing thinking states');
                    animationModule.thinkingStates.forEach((state, index) => {
                        setTimeout(() => {
                            console.log(`Testing thinking state ${index + 1}: ${state.name}`);
                            animationModule.setToThinkingState(index);
                        }, index * 1000);
                    });
                    
                    setTimeout(() => {
                        console.log('Testing talking animation (images)');
                        animationModule.startTalkingAnimation();
                        
                        // Return to idle after testing
                        setTimeout(() => {
                            animationModule.stopTalkingAnimation();
                            console.log('‚úÖ Debug test completed - returned to idle');
                        }, 3000);
                    }, 2000);
                }, 1000);
            }
            
            // Language toggle functionality
            let currentLanguage = 'en';
            
            // Burger menu toggle
            function toggleBurgerMenu() {
                const menu = document.getElementById('burger-menu');
                if (menu) {
                    const isVisible = menu.style.display !== 'none';
                    menu.style.display = isVisible ? 'none' : 'block';
                }
            }
            
            // Close burger menu when clicking outside
            document.addEventListener('click', function(event) {
                const menu = document.getElementById('burger-menu');
                const btn = document.getElementById('burger-menu-btn');
                if (menu && btn && !menu.contains(event.target) && !btn.contains(event.target)) {
                    menu.style.display = 'none';
                }
            });
            
            window.toggleBurgerMenu = toggleBurgerMenu; // Expose burger menu toggle
            
            function toggleLanguage() {
                currentLanguage = currentLanguage === 'en' ? 'es' : 'en';
                window.currentLanguage = currentLanguage; // Update global for project UI
                const button = document.getElementById('language-toggle');
                if (button) button.textContent = currentLanguage.toUpperCase();
                const langDisplay = document.getElementById('lang-display');
                if (langDisplay) langDisplay.textContent = currentLanguage.toUpperCase();
                updateButtonText();
                if (window.updateTalkingControllerLanguage) {
                    window.updateTalkingControllerLanguage(currentLanguage);
                }
            }
            
            function updateButtonText() {
                // Button is now in project UI file, so check if it exists
                const button = document.getElementById('ask-question-btn');
                if (!button) {
                    // Button not loaded yet (project UI not loaded), skip
                    return;
                }
                
                if (currentLanguage === 'es') {
                    button.textContent = 'Hacer Pregunta';
                } else {
                    button.textContent = 'Ask Question';
                }
            }
            
            // Initialize button text (only if button exists - project UI may not be loaded yet)
            // This will be called again after project UI loads
            updateButtonText();
            
            // Expose functions globally for external control
            window.startTalkingAnimation = startTalkingAnimation;
            window.stopTalkingAnimation = stopTalkingAnimation;
            window.startThinkingAnimation = startThinkingAnimation;
            window.stopThinkingAnimation = stopThinkingAnimation;
            window.stopAudio = stopAudio;
            // askQuestion is already assigned to window at definition (line 1847)
            window.toggleLanguage = toggleLanguage; // Expose language toggle
            window.animationModule = animationModule; // Expose for console debugging
            
            // Test animation functions (single play mode) - define early so buttons can use them
            window.testThinkingAnimation = function() {
                console.log('üß™ Testing thinking animation (one cycle)...');
                // Stop any existing animations
                if (window.stopTalkingAnimation) window.stopTalkingAnimation();
                if (window.stopThinkingAnimation) window.stopThinkingAnimation();
                // Small delay to ensure previous animation is fully stopped
                setTimeout(() => {
                    // Reset state before starting
                    if (window.animationModule) {
                        window.animationModule.currentThinkingFrame = 0;
                        window.animationModule.currentThinkingState = 0;
                        window.animationModule.isThinking = false;
                    }
                    // Test mode: single play (no loop), with audio
                    if (window.thinkingController) {
                        window.thinkingController.start({ loop: false, playAudio: true });
                    } else {
                        console.error('‚ùå thinkingController not available');
                    }
                }, 150);
            };
            
            window.testTalkingAnimation = function() {
                console.log('üß™ Testing talking animation (one cycle with intro)...');
                // Stop any existing animations
                if (window.stopTalkingAnimation) window.stopTalkingAnimation();
                if (window.stopThinkingAnimation) window.stopThinkingAnimation();
                // Small delay to ensure previous animation is fully stopped
                setTimeout(() => {
                    // Reset state before starting
                    if (window.animationModule) {
                        window.animationModule.currentTalkingFrame = 0;
                        window.animationModule.currentTalkingState = 0;
                        window.animationModule.talkingDirection = 1;
                        window.animationModule.isTalking = false;
                    }
                    // Test mode: single play (no loop) with intro audio
                    if (window.talkingController) {
                        window.talkingController.start({ loop: false, playIntro: true });
                    } else {
                        console.error('‚ùå talkingController not available');
                    }
                }, 150);
            };
            
            const marker = document.querySelector('#ar-marker');
            if (marker) {
                // Enhanced smoothing with frame averaging and dead zone filtering
                let lastPosition = { x: 0, y: 0, z: 0 };
                let lastRotation = { x: 0, y: 0, z: 0 };
                
                // Much more aggressive smoothing to eliminate wobble
                let smoothingFactor = 0.05; // Very aggressive smoothing (lower = more stable, less jitter)
                let rotationSmoothing = 0.04; // Extremely aggressive rotation smoothing
                
                // Frame averaging buffer for additional stability
                const POSITION_BUFFER_SIZE = 5; // Average over 5 frames
                const ROTATION_BUFFER_SIZE = 5;
                let positionBuffer = [];
                let rotationBuffer = [];
                
                // Dead zone filtering - ignore tiny movements (likely autofocus wobble)
                const POSITION_DEAD_ZONE = 0.0005; // Ignore movements smaller than this (in meters)
                const ROTATION_DEAD_ZONE = 0.1; // Ignore rotations smaller than this (in degrees)
                
                // Velocity-based filtering - filter out sudden high-velocity changes
                let lastVelocity = { x: 0, y: 0, z: 0 };
                let lastRotationVelocity = { x: 0, y: 0, z: 0 };
                const MAX_VELOCITY = 0.01; // Maximum allowed velocity per frame (m/frame)
                const MAX_ROTATION_VELOCITY = 2.0; // Maximum allowed rotation velocity (deg/frame)
                
                let trackingStability = 0; // Track how stable tracking is (0-1)
                let consecutiveFrames = 0; // Count consecutive successful tracking frames
                
                // Hysteresis: Keep entity visible for longer time after target lost for better stability
                let targetLostTimeout = null;
                let isTargetVisible = false;
                const TARGET_LOST_DELAY = 1500; // Keep visible for 1.5s after losing target (much longer for stability)
                const MIN_STABLE_FRAMES = 3; // Lower threshold - consider stable after just 3 frames
                
                // Position tracking for debugging
                let positionLogCount = 0;
                let rotationLogCount = 0;
                let lastLoggedPosition = null;
                let lastLoggedRotation = null;
                let positionDeltas = [];
                let rotationDeltas = [];
                const LOG_INTERVAL = 30; // Log every 30 frames
                const MAX_DELTA_HISTORY = 100; // Keep last 100 deltas for analysis
                
                // Tracking loss detection
                let lastPositionUpdateTime = 0;
                let lastRotationUpdateTime = 0;
                let trackingLossEvents = [];
                let lastTargetLostTime = 0;
                const POSITION_UPDATE_TIMEOUT = 200; // If no position update for 200ms, consider tracking lost
                const ROTATION_UPDATE_TIMEOUT = 200; // If no rotation update for 200ms, consider tracking lost
                
                console.log('üéØ [TRACKING] Setting up tracking event listeners...');
                
                // Track if we've loaded the project UI (only load once)
                let projectUILoaded = false;
                
                marker.addEventListener('targetFound', function() {
                    console.log('‚úÖ [TRACKING] Target FOUND - Marker detected!');
                    consecutiveFrames++;
                    
                    // Load project-specific UI on first detection (only once)
                    if (consecutiveFrames === 1 && !projectUILoaded && currentTarget && currentTarget.userId && currentTarget.projectName) {
                        console.log('üì¶ Loading project UI for detected target...');
                        loadProjectUI(currentTarget.userId, currentTarget.projectName).then(() => {
                            projectUILoaded = true;
                        }).catch(err => {
                            console.warn('‚ö†Ô∏è Failed to load project UI:', err);
                        });
                    }
                    
                    // Log first detection and milestones
                    if (consecutiveFrames === 1) {
                        console.log('üéØ MARKER DETECTED!');
                    }
                    
                    // Increase smoothing as tracking becomes more stable
                    if (consecutiveFrames > MIN_STABLE_FRAMES) {
                        trackingStability = Math.min(1.0, trackingStability + 0.1);
                        // Keep very aggressive smoothing even when stable to eliminate wobble
                        // Only slightly reduce smoothing for minimal responsiveness
                        smoothingFactor = Math.max(0.04, 0.06 - (trackingStability * 0.01));
                        rotationSmoothing = Math.max(0.03, 0.05 - (trackingStability * 0.01));
                    }
                    
                    // Less verbose logging - only log every 60 frames or milestones
                    if (consecutiveFrames % 60 === 0 || consecutiveFrames === MIN_STABLE_FRAMES + 1) {
                        console.log(`üéØ Tracking stable (${consecutiveFrames} frames, ${(trackingStability * 100).toFixed(0)}% stable)`);
                    }
                    
                    isTargetVisible = true;
                    
                    // Clear any pending hide timeout
                    if (targetLostTimeout) {
                        clearTimeout(targetLostTimeout);
                        targetLostTimeout = null;
                    }
                    
                    // Ensure all child entities are visible
                    const markerMesh = marker.getObject3D('mesh');
                    if (markerMesh) {
                        markerMesh.visible = true;
                        markerMesh.traverse((child) => {
                            if (child.isMesh) {
                                child.visible = true;
                            }
                        });
                    }
                    
                    // Also ensure orange plane is visible
                    const orangePlaneMesh = orangePlane.getObject3D('mesh');
                    if (orangePlaneMesh) {
                        orangePlaneMesh.visible = true;
                    }
                    
                    // Show project UI when target is found (if it's been loaded)
                    const projectUIContainer = document.getElementById('project-ui-container');
                    if (projectUIContainer && projectUIContainer.innerHTML.trim() !== '') {
                        projectUIContainer.style.display = 'block';
                        console.log('üëÅÔ∏è Showing project UI (target found)');
                    }
                });
                
                marker.addEventListener('targetLost', function() {
                    console.log('‚ùå [TRACKING] Target LOST - Marker no longer detected!');
                    
                    // Hide project UI when target is lost (but don't remove it, just hide)
                    const projectUIContainer = document.getElementById('project-ui-container');
                    if (projectUIContainer && projectUIContainer.innerHTML.trim() !== '') {
                        projectUIContainer.style.display = 'none';
                        console.log('üëÅÔ∏è Hiding project UI (target lost)');
                    }
                    
                    const now = performance.now();
                    const timeSinceLastLoss = now - lastTargetLostTime;
                    lastTargetLostTime = now;
                    
                    // Don't reset stability immediately - decay it slowly for better continuity
                    // Only reset if we never got stable
                    if (consecutiveFrames < MIN_STABLE_FRAMES) {
                        trackingStability = Math.max(0, trackingStability - 0.2);
                    } else {
                        // Decay stability slowly on loss - keep some memory of stability
                        trackingStability = Math.max(0, trackingStability - 0.05);
                    }
                    const lostFrames = consecutiveFrames;
                    const wasStable = lostFrames >= MIN_STABLE_FRAMES;
                    consecutiveFrames = 0;
                    
                    // Log ALL tracking losses with detailed information
                    const lossInfo = {
                        frames: lostFrames,
                        wasStable: wasStable,
                        stability: (trackingStability * 100).toFixed(1) + '%',
                        timeSinceLastLoss: timeSinceLastLoss > 0 ? timeSinceLastLoss.toFixed(0) + 'ms' : 'first loss',
                        visibilityDelay: TARGET_LOST_DELAY + 'ms',
                        timestamp: new Date().toISOString()
                    };
                    
                    // Always log tracking loss - use different log levels based on significance
                    if (lostFrames === 0) {
                        console.warn('‚ùå‚ùå‚ùå TRACKING LOST (0 frames - immediate loss)', lossInfo);
                    } else if (lostFrames < MIN_STABLE_FRAMES) {
                        console.warn(`‚ùå TRACKING LOST (${lostFrames} frames - unstable)`, lossInfo);
                    } else if (lostFrames < 10) {
                        console.warn(`‚ö†Ô∏è TRACKING LOST (${lostFrames} frames - brief stable)`, lossInfo);
                    } else {
                        console.log(`‚ö†Ô∏è Target lost (${lostFrames} frames - was stable)`, lossInfo);
                    }
                    
                    // Track loss events for analysis
                    if (trackingLossEvents.length >= 50) {
                        trackingLossEvents.shift();
                    }
                    trackingLossEvents.push({
                        ...lossInfo,
                        time: now
                    });
                    
                    // Schedule hide after delay (hysteresis) - longer delay for stability
                    if (targetLostTimeout) {
                        clearTimeout(targetLostTimeout);
                        console.log('‚è∏Ô∏è Cancelled previous hide timeout, rescheduling...');
                    }
                    
                    console.log(`‚è≥ Scheduling hide in ${TARGET_LOST_DELAY}ms if target not found...`);
                    targetLostTimeout = setTimeout(() => {
                        if (!isTargetVisible) {
                            const markerMesh = marker.getObject3D('mesh');
                            const orangePlaneMesh = orangePlane.getObject3D('mesh');
                            const actuallyHidden = markerMesh && !markerMesh.visible;
                            
                            console.log('üëã Hiding entity after tracking loss timeout', {
                                markerVisible: markerMesh ? markerMesh.visible : 'no mesh',
                                orangePlaneVisible: orangePlaneMesh ? orangePlaneMesh.visible : 'no mesh',
                                wasAlreadyHidden: actuallyHidden,
                                timeSinceLoss: (performance.now() - now).toFixed(0) + 'ms'
                            });
                            
                            if (markerMesh) {
                                markerMesh.visible = false;
                            }
                            if (orangePlaneMesh) {
                                orangePlaneMesh.visible = false;
                            }
                        } else {
                            console.log('‚úÖ Target found again before hide timeout - keeping visible');
                        }
                    }, TARGET_LOST_DELAY);
                    
                    isTargetVisible = false;
                });
                
                // Add smoothing to marker position and rotation
                // Simple direct smoothing: smoothly interpolate from last position to current position
                marker.addEventListener('componentchanged', function(event) {
                    const now = performance.now();
                    
                    if (event.detail.name === 'position') {
                        // Check if we had a gap in position updates (potential tracking loss)
                        if (lastPositionUpdateTime > 0 && (now - lastPositionUpdateTime) > POSITION_UPDATE_TIMEOUT) {
                            const gap = now - lastPositionUpdateTime;
                            console.warn(`‚ö†Ô∏è Position update gap detected: ${gap.toFixed(0)}ms (possible tracking loss)`);
                        }
                        
                        lastPositionUpdateTime = now;
                        
                        const currentPos = marker.getAttribute('position');
                        if (currentPos) {
                            const current = {
                                x: parseFloat(currentPos.x),
                                y: parseFloat(currentPos.y),
                                z: parseFloat(currentPos.z)
                            };
                            
                            // Initialize lastPosition on first update
                            if (lastPosition.x === 0 && lastPosition.y === 0 && lastPosition.z === 0) {
                                lastPosition = { ...current };
                                lastLoggedPosition = { ...current };
                                console.log('üìç Position tracking initialized:', current);
                            }
                            
                            // Calculate raw delta (how much the raw position changed)
                            const rawDelta = {
                                x: current.x - (lastLoggedPosition ? lastLoggedPosition.x : current.x),
                                y: current.y - (lastLoggedPosition ? lastLoggedPosition.y : current.y),
                                z: current.z - (lastLoggedPosition ? lastLoggedPosition.z : current.z)
                            };
                            const rawDeltaMagnitude = Math.sqrt(rawDelta.x**2 + rawDelta.y**2 + rawDelta.z**2);
                            
                            // Calculate velocity (change per frame)
                            const velocity = {
                                x: current.x - lastPosition.x,
                                y: current.y - lastPosition.y,
                                z: current.z - lastPosition.z
                            };
                            const velocityMagnitude = Math.sqrt(velocity.x**2 + velocity.y**2 + velocity.z**2);
                            
                            // Velocity-based filtering: reject sudden high-velocity changes (likely noise)
                            let filteredCurrent = { ...current };
                            if (velocityMagnitude > MAX_VELOCITY) {
                                // Clamp velocity to maximum allowed
                                const scale = MAX_VELOCITY / velocityMagnitude;
                                filteredCurrent = {
                                    x: lastPosition.x + velocity.x * scale,
                                    y: lastPosition.y + velocity.y * scale,
                                    z: lastPosition.z + velocity.z * scale
                                };
                            }
                            
                            // Add to frame buffer for averaging
                            positionBuffer.push(filteredCurrent);
                            if (positionBuffer.length > POSITION_BUFFER_SIZE) {
                                positionBuffer.shift();
                            }
                            
                            // Calculate averaged position from buffer
                            const avgPosition = {
                                x: positionBuffer.reduce((sum, p) => sum + p.x, 0) / positionBuffer.length,
                                y: positionBuffer.reduce((sum, p) => sum + p.y, 0) / positionBuffer.length,
                                z: positionBuffer.reduce((sum, p) => sum + p.z, 0) / positionBuffer.length
                            };
                            
                            // Dead zone filtering: ignore movements smaller than threshold
                            const deltaFromLast = {
                                x: avgPosition.x - lastPosition.x,
                                y: avgPosition.y - lastPosition.y,
                                z: avgPosition.z - lastPosition.z
                            };
                            const deltaMagnitude = Math.sqrt(deltaFromLast.x**2 + deltaFromLast.y**2 + deltaFromLast.z**2);
                            
                            // Apply dead zone - if movement is too small, don't update
                            let finalPosition = lastPosition;
                            let adaptiveSmoothing = smoothingFactor; // Default value
                            if (deltaMagnitude >= POSITION_DEAD_ZONE) {
                                // Use very aggressive smoothing with averaged position
                                adaptiveSmoothing = isTargetVisible && consecutiveFrames > MIN_STABLE_FRAMES 
                                ? smoothingFactor 
                                    : smoothingFactor * 2.0; // Much more smoothing when unstable (startup)
                                
                                finalPosition = {
                                    x: lastPosition.x + (avgPosition.x - lastPosition.x) * adaptiveSmoothing,
                                    y: lastPosition.y + (avgPosition.y - lastPosition.y) * adaptiveSmoothing,
                                    z: lastPosition.z + (avgPosition.z - lastPosition.z) * adaptiveSmoothing
                                };
                            }
                            
                            // Calculate smoothed delta
                            const smoothedDelta = {
                                x: finalPosition.x - lastPosition.x,
                                y: finalPosition.y - lastPosition.y,
                                z: finalPosition.z - lastPosition.z
                            };
                            const smoothedDeltaMagnitude = Math.sqrt(smoothedDelta.x**2 + smoothedDelta.y**2 + smoothedDelta.z**2);
                            
                            // Update velocity for next frame
                            lastVelocity = velocity;
                            
                            // Track deltas for analysis
                            if (positionDeltas.length >= MAX_DELTA_HISTORY) {
                                positionDeltas.shift();
                            }
                            positionDeltas.push({
                                raw: rawDeltaMagnitude,
                                smoothed: smoothedDeltaMagnitude,
                                frame: consecutiveFrames,
                                timestamp: performance.now()
                            });
                            
                            lastPosition = finalPosition;
                            marker.setAttribute('position', `${finalPosition.x} ${finalPosition.y} ${finalPosition.z}`);
                            
                            // Log position data periodically
                            positionLogCount++;
                            if (positionLogCount % LOG_INTERVAL === 0 || rawDeltaMagnitude > 0.01) {
                                const avgRawDelta = positionDeltas.slice(-30).reduce((sum, d) => sum + d.raw, 0) / Math.min(30, positionDeltas.length);
                                const avgSmoothedDelta = positionDeltas.slice(-30).reduce((sum, d) => sum + d.smoothed, 0) / Math.min(30, positionDeltas.length);
                                const maxRawDelta = Math.max(...positionDeltas.slice(-30).map(d => d.raw));
                                
                                console.log(`üìç Position [Frame ${consecutiveFrames}]`, {
                                    raw: `(${current.x.toFixed(4)}, ${current.y.toFixed(4)}, ${current.z.toFixed(4)})`,
                                    averaged: `(${avgPosition.x.toFixed(4)}, ${avgPosition.y.toFixed(4)}, ${avgPosition.z.toFixed(4)})`,
                                    smoothed: `(${finalPosition.x.toFixed(4)}, ${finalPosition.y.toFixed(4)}, ${finalPosition.z.toFixed(4)})`,
                                    rawDelta: rawDeltaMagnitude.toFixed(6),
                                    velocity: velocityMagnitude.toFixed(6),
                                    smoothedDelta: smoothedDeltaMagnitude.toFixed(6),
                                    deadZoneFiltered: deltaMagnitude < POSITION_DEAD_ZONE,
                                    smoothing: adaptiveSmoothing.toFixed(4),
                                    stability: `${(trackingStability * 100).toFixed(0)}%`,
                                    avgRawDelta: avgRawDelta.toFixed(6),
                                    avgSmoothedDelta: avgSmoothedDelta.toFixed(6),
                                    maxRawDelta: maxRawDelta.toFixed(6),
                                    visible: isTargetVisible
                                });
                                
                                // Warn if jitter is high
                                if (rawDeltaMagnitude > 0.05 || maxRawDelta > 0.1) {
                                    console.warn(`‚ö†Ô∏è High position jitter detected! Raw delta: ${rawDeltaMagnitude.toFixed(6)}, Max: ${maxRawDelta.toFixed(6)}`);
                                }
                            }
                            
                            lastLoggedPosition = { ...current };
                        }
                    } else if (event.detail.name === 'rotation') {
                        // Check if we had a gap in rotation updates (potential tracking loss)
                        if (lastRotationUpdateTime > 0 && (now - lastRotationUpdateTime) > ROTATION_UPDATE_TIMEOUT) {
                            const gap = now - lastRotationUpdateTime;
                            console.warn(`‚ö†Ô∏è Rotation update gap detected: ${gap.toFixed(0)}ms (possible tracking loss)`);
                        }
                        
                        lastRotationUpdateTime = now;
                        
                        const currentRot = marker.getAttribute('rotation');
                        if (currentRot) {
                            const current = {
                                x: parseFloat(currentRot.x),
                                y: parseFloat(currentRot.y),
                                z: parseFloat(currentRot.z)
                            };
                            
                            // Initialize lastRotation on first update
                            if (lastRotation.x === 0 && lastRotation.y === 0 && lastRotation.z === 0) {
                                lastRotation = { ...current };
                                lastLoggedRotation = { ...current };
                                console.log('üîÑ Rotation tracking initialized:', current);
                            }
                            
                            // Calculate raw delta (how much the raw rotation changed)
                            const rawDelta = {
                                x: current.x - (lastLoggedRotation ? lastLoggedRotation.x : current.x),
                                y: current.y - (lastLoggedRotation ? lastLoggedRotation.y : current.y),
                                z: current.z - (lastLoggedRotation ? lastLoggedRotation.z : current.z)
                            };
                            // Normalize rotation deltas (handle wrap-around)
                            const normalizeAngle = (angle) => {
                                while (angle > 180) angle -= 360;
                                while (angle < -180) angle += 360;
                                return angle;
                            };
                            rawDelta.x = normalizeAngle(rawDelta.x);
                            rawDelta.y = normalizeAngle(rawDelta.y);
                            rawDelta.z = normalizeAngle(rawDelta.z);
                            const rawDeltaMagnitude = Math.sqrt(rawDelta.x**2 + rawDelta.y**2 + rawDelta.z**2);
                            
                            // Calculate rotation velocity (change per frame)
                            const rotationVelocity = {
                                x: normalizeAngle(current.x - lastRotation.x),
                                y: normalizeAngle(current.y - lastRotation.y),
                                z: normalizeAngle(current.z - lastRotation.z)
                            };
                            const rotationVelocityMagnitude = Math.sqrt(rotationVelocity.x**2 + rotationVelocity.y**2 + rotationVelocity.z**2);
                            
                            // Velocity-based filtering: reject sudden high-velocity changes (likely noise)
                            let filteredCurrent = { ...current };
                            if (rotationVelocityMagnitude > MAX_ROTATION_VELOCITY) {
                                // Clamp velocity to maximum allowed
                                const scale = MAX_ROTATION_VELOCITY / rotationVelocityMagnitude;
                                filteredCurrent = {
                                    x: normalizeAngle(lastRotation.x + rotationVelocity.x * scale),
                                    y: normalizeAngle(lastRotation.y + rotationVelocity.y * scale),
                                    z: normalizeAngle(lastRotation.z + rotationVelocity.z * scale)
                                };
                            }
                            
                            // Add to frame buffer for averaging
                            rotationBuffer.push(filteredCurrent);
                            if (rotationBuffer.length > ROTATION_BUFFER_SIZE) {
                                rotationBuffer.shift();
                            }
                            
                            // Calculate averaged rotation from buffer
                            const avgRotation = {
                                x: rotationBuffer.reduce((sum, r) => sum + normalizeAngle(r.x), 0) / rotationBuffer.length,
                                y: rotationBuffer.reduce((sum, r) => sum + normalizeAngle(r.y), 0) / rotationBuffer.length,
                                z: rotationBuffer.reduce((sum, r) => sum + normalizeAngle(r.z), 0) / rotationBuffer.length
                            };
                            
                            // Dead zone filtering: ignore rotations smaller than threshold
                            const deltaFromLast = {
                                x: normalizeAngle(avgRotation.x - lastRotation.x),
                                y: normalizeAngle(avgRotation.y - lastRotation.y),
                                z: normalizeAngle(avgRotation.z - lastRotation.z)
                            };
                            const deltaMagnitude = Math.sqrt(deltaFromLast.x**2 + deltaFromLast.y**2 + deltaFromLast.z**2);
                            
                            // Apply dead zone - if rotation is too small, don't update
                            let finalRotation = lastRotation;
                            let adaptiveRotationSmoothing = rotationSmoothing; // Default value
                            if (deltaMagnitude >= ROTATION_DEAD_ZONE) {
                                // Use very aggressive smoothing with averaged rotation
                                adaptiveRotationSmoothing = isTargetVisible && consecutiveFrames > MIN_STABLE_FRAMES 
                                ? rotationSmoothing 
                                    : rotationSmoothing * 2.5; // Much more smoothing when unstable (startup)
                                
                                finalRotation = {
                                    x: normalizeAngle(lastRotation.x + normalizeAngle(avgRotation.x - lastRotation.x) * adaptiveRotationSmoothing),
                                    y: normalizeAngle(lastRotation.y + normalizeAngle(avgRotation.y - lastRotation.y) * adaptiveRotationSmoothing),
                                    z: normalizeAngle(lastRotation.z + normalizeAngle(avgRotation.z - lastRotation.z) * adaptiveRotationSmoothing)
                                };
                            }
                            
                            // Calculate smoothed delta
                            const smoothedDelta = {
                                x: normalizeAngle(finalRotation.x - lastRotation.x),
                                y: normalizeAngle(finalRotation.y - lastRotation.y),
                                z: normalizeAngle(finalRotation.z - lastRotation.z)
                            };
                            const smoothedDeltaMagnitude = Math.sqrt(smoothedDelta.x**2 + smoothedDelta.y**2 + smoothedDelta.z**2);
                            
                            // Update rotation velocity for next frame
                            lastRotationVelocity = rotationVelocity;
                            
                            // Track deltas for analysis
                            if (rotationDeltas.length >= MAX_DELTA_HISTORY) {
                                rotationDeltas.shift();
                            }
                            rotationDeltas.push({
                                raw: rawDeltaMagnitude,
                                smoothed: smoothedDeltaMagnitude,
                                frame: consecutiveFrames,
                                timestamp: performance.now()
                            });
                            
                            lastRotation = finalRotation;
                            marker.setAttribute('rotation', `${finalRotation.x} ${finalRotation.y} ${finalRotation.z}`);
                            
                            // Log rotation data periodically
                            rotationLogCount++;
                            if (rotationLogCount % LOG_INTERVAL === 0 || rawDeltaMagnitude > 2.0) {
                                const avgRawDelta = rotationDeltas.slice(-30).reduce((sum, d) => sum + d.raw, 0) / Math.min(30, rotationDeltas.length);
                                const avgSmoothedDelta = rotationDeltas.slice(-30).reduce((sum, d) => sum + d.smoothed, 0) / Math.min(30, rotationDeltas.length);
                                const maxRawDelta = Math.max(...rotationDeltas.slice(-30).map(d => d.raw));
                                
                                console.log(`üîÑ Rotation [Frame ${consecutiveFrames}]`, {
                                    raw: `(${current.x.toFixed(2)}¬∞, ${current.y.toFixed(2)}¬∞, ${current.z.toFixed(2)}¬∞)`,
                                    averaged: `(${avgRotation.x.toFixed(2)}¬∞, ${avgRotation.y.toFixed(2)}¬∞, ${avgRotation.z.toFixed(2)}¬∞)`,
                                    smoothed: `(${finalRotation.x.toFixed(2)}¬∞, ${finalRotation.y.toFixed(2)}¬∞, ${finalRotation.z.toFixed(2)}¬∞)`,
                                    rawDelta: `${rawDeltaMagnitude.toFixed(4)}¬∞`,
                                    velocity: `${rotationVelocityMagnitude.toFixed(4)}¬∞`,
                                    smoothedDelta: `${smoothedDeltaMagnitude.toFixed(4)}¬∞`,
                                    deadZoneFiltered: deltaMagnitude < ROTATION_DEAD_ZONE,
                                    smoothing: adaptiveRotationSmoothing.toFixed(4),
                                    stability: `${(trackingStability * 100).toFixed(0)}%`,
                                    avgRawDelta: `${avgRawDelta.toFixed(4)}¬∞`,
                                    avgSmoothedDelta: `${avgSmoothedDelta.toFixed(4)}¬∞`,
                                    maxRawDelta: `${maxRawDelta.toFixed(4)}¬∞`,
                                    visible: isTargetVisible
                                });
                                
                                // Warn if jitter is high
                                if (rawDeltaMagnitude > 5.0 || maxRawDelta > 10.0) {
                                    console.warn(`‚ö†Ô∏è High rotation jitter detected! Raw delta: ${rawDeltaMagnitude.toFixed(4)}¬∞, Max: ${maxRawDelta.toFixed(4)}¬∞`);
                                }
                            }
                            
                            lastLoggedRotation = { ...current };
                        }
                    }
                });
                
                // Monitor for tracking loss by checking update timeouts
                setInterval(() => {
                    const now = performance.now();
                    const timeSincePositionUpdate = now - lastPositionUpdateTime;
                    const timeSinceRotationUpdate = now - lastRotationUpdateTime;
                    
                    // Check if updates have stopped (tracking may have been lost without event firing)
                    if (isTargetVisible && lastPositionUpdateTime > 0) {
                        if (timeSincePositionUpdate > POSITION_UPDATE_TIMEOUT && timeSinceRotationUpdate > ROTATION_UPDATE_TIMEOUT) {
                            console.error(`üö® TRACKING LOSS DETECTED: No position/rotation updates for ${Math.max(timeSincePositionUpdate, timeSinceRotationUpdate).toFixed(0)}ms`);
                            console.error('   This suggests tracking was lost but targetLost event did not fire!');
                            console.error('   Position gap:', timeSincePositionUpdate.toFixed(0) + 'ms');
                            console.error('   Rotation gap:', timeSinceRotationUpdate.toFixed(0) + 'ms');
                            console.error('   isTargetVisible:', isTargetVisible);
                            console.error('   consecutiveFrames:', consecutiveFrames);
                        }
                    }
                }, 100); // Check every 100ms
                
                // Periodic summary logging
                setInterval(() => {
                    if (positionDeltas.length > 0 && rotationDeltas.length > 0) {
                        const posStats = {
                            count: positionDeltas.length,
                            avgRaw: (positionDeltas.reduce((sum, d) => sum + d.raw, 0) / positionDeltas.length).toFixed(6),
                            avgSmoothed: (positionDeltas.reduce((sum, d) => sum + d.smoothed, 0) / positionDeltas.length).toFixed(6),
                            maxRaw: Math.max(...positionDeltas.map(d => d.raw)).toFixed(6),
                            minRaw: Math.min(...positionDeltas.map(d => d.raw)).toFixed(6)
                        };
                        const rotStats = {
                            count: rotationDeltas.length,
                            avgRaw: (rotationDeltas.reduce((sum, d) => sum + d.raw, 0) / rotationDeltas.length).toFixed(4),
                            avgSmoothed: (rotationDeltas.reduce((sum, d) => sum + d.smoothed, 0) / rotationDeltas.length).toFixed(4),
                            maxRaw: Math.max(...rotationDeltas.map(d => d.raw)).toFixed(4),
                            minRaw: Math.min(...rotationDeltas.map(d => d.raw)).toFixed(4)
                        };
                        
                        const recentLosses = trackingLossEvents.slice(-10);
                        const lossStats = recentLosses.length > 0 ? {
                            count: recentLosses.length,
                            avgFrames: (recentLosses.reduce((sum, e) => sum + e.frames, 0) / recentLosses.length).toFixed(1),
                            totalLosses: trackingLossEvents.length
                        } : { count: 0, totalLosses: trackingLossEvents.length };
                        
                        console.log('üìä Tracking Summary [Last 100 frames]', {
                            frames: consecutiveFrames,
                            stability: `${(trackingStability * 100).toFixed(0)}%`,
                            isVisible: isTargetVisible,
                            position: posStats,
                            rotation: rotStats,
                            smoothingFactor: smoothingFactor.toFixed(4),
                            rotationSmoothing: rotationSmoothing.toFixed(4),
                            trackingLosses: lossStats,
                            timeSincePositionUpdate: lastPositionUpdateTime > 0 ? (performance.now() - lastPositionUpdateTime).toFixed(0) + 'ms' : 'never',
                            timeSinceRotationUpdate: lastRotationUpdateTime > 0 ? (performance.now() - lastRotationUpdateTime).toFixed(0) + 'ms' : 'never'
                        });
                    }
                }, 5000); // Every 5 seconds
                
                // Expose tracking debug data
                window.trackingDebug = {
                    getPosition: () => {
                        const pos = marker.getAttribute('position');
                        return pos ? { x: parseFloat(pos.x), y: parseFloat(pos.y), z: parseFloat(pos.z) } : null;
                    },
                    getRotation: () => {
                        const rot = marker.getAttribute('rotation');
                        return rot ? { x: parseFloat(rot.x), y: parseFloat(rot.y), z: parseFloat(rot.z) } : null;
                    },
                    getStats: () => {
                        const now = performance.now();
                        return {
                            consecutiveFrames,
                            trackingStability: (trackingStability * 100).toFixed(2) + '%',
                            isTargetVisible,
                            smoothingFactor: smoothingFactor.toFixed(4),
                            rotationSmoothing: rotationSmoothing.toFixed(4),
                            positionDeltas: positionDeltas.slice(-30),
                            rotationDeltas: rotationDeltas.slice(-30),
                            lastPosition,
                            lastRotation,
                            positionHistory: positionDeltas,
                            rotationHistory: rotationDeltas,
                            trackingLosses: trackingLossEvents,
                            recentLosses: trackingLossEvents.slice(-10),
                            timeSincePositionUpdate: lastPositionUpdateTime > 0 ? (now - lastPositionUpdateTime).toFixed(0) + 'ms' : 'never',
                            timeSinceRotationUpdate: lastRotationUpdateTime > 0 ? (now - lastRotationUpdateTime).toFixed(0) + 'ms' : 'never',
                            lastTargetLostTime: lastTargetLostTime > 0 ? (now - lastTargetLostTime).toFixed(0) + 'ms ago' : 'never'
                        };
                    },
                    clearHistory: () => {
                        positionDeltas = [];
                        rotationDeltas = [];
                        console.log('‚úÖ Tracking history cleared');
                    },
                    getOrangePlanePosition: () => {
                        const pos = orangePlane.getAttribute('position');
                        return pos ? { x: parseFloat(pos.x), y: parseFloat(pos.y), z: parseFloat(pos.z) } : null;
                    },
                    getOrangePlaneRotation: () => {
                        const rot = orangePlane.getAttribute('rotation');
                        return rot ? { x: parseFloat(rot.x), y: parseFloat(rot.y), z: parseFloat(rot.z) } : null;
                    }
                };
                console.log('üîß Tracking debug tools available:');
                console.log('  - window.trackingDebug.getStats() - Get current tracking statistics');
                console.log('  - window.trackingDebug.getPosition() - Get marker position');
                console.log('  - window.trackingDebug.getRotation() - Get marker rotation');
                console.log('  - window.trackingDebug.getOrangePlanePosition() - Get orange plane position');
                console.log('  - window.trackingDebug.getOrangePlaneRotation() - Get orange plane rotation');
                console.log('  - window.trackingDebug.clearHistory() - Clear tracking history');
            }
    </script>
</body>
</html>
